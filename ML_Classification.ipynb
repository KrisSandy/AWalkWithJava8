{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML - Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/KrisSandy/AWalkWithJava8/blob/master/ML_Classification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "blkY-k_h6sLb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning | Classification"
      ]
    },
    {
      "metadata": {
        "id": "x8dITrSWBNf_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this assignment I have choosen scikit-learn library which is an open source package developed in python. scikit-learn along with other scientific packages in python provides powerful data structures and machine learning features which can be leveraged with ease.\n",
        "\n",
        "Besides readily available implementation of K nearest Neighbours algorithm, below are some of the main reasons for choosing scikit-learn\n",
        "\n",
        "\n",
        "1.   scikit-learn is open source package\n",
        "2.   Its regularly updated with more than 1 release per year which means the packages are up to date.\n",
        "3. Easy to use \n",
        "4. It has implementations for most of the machine learning tasks such as Clustering, Classification, Regression etc.\n",
        "5. Very good and up to date documentation available.\n",
        "\n",
        "scikit-learn offers below features:\n",
        "\n",
        "\n",
        "1.   Preprocessing - to transform, extract features and normalize the data\n",
        "2.   Functions to perform Classification, Regression, Clustering \n",
        "3. Dimensionality reduction \n",
        "4. Model Selection\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Reference: https://www.oreilly.com/ideas/six-reasons-why-i-recommend-scikit-learn*\n",
        "\n",
        "*Reference: http://scikit-learn.org/stable/index.html*"
      ]
    },
    {
      "metadata": {
        "id": "odZw_zWzYT0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Connecting with Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "jEaCinr99HbE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Configuring Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "h2vSH1Bg6wLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "cad4bbe7-2858-4c60-b09b-5a2a90040105"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMuqOP02XQCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verify google drive connection"
      ]
    },
    {
      "metadata": {
        "id": "z2UIAvm78Fx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "714f9799-b838-4f22-8fc6-df66467e6d88"
      },
      "cell_type": "code",
      "source": [
        "!cat /content/gdrive/My\\ Drive/GYE06/CT475_ML/autoimmune.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\t22\t21\t23\t25\t25\t35\t22\t23\t23\t21\t28\t54\t25\t43\t42\t21\t25\t23\t26\t24\t24\t31\t22\t60\t51\t37\t41\t28\t21\t22\t25\t34\t29\t24\t26\t28\t32\t24\t29\t24\t61\t63\t25\t34\t25\t24\t24\t28\t21\t46\t30\t25\t23\t33\t40\t29\t28\t38\t22\t21\t33\t31\t26\t21\t25\t22\t40\t24\t25\t23\t25\t25\t33\t24\t24\t22\t56\t27\t47\t23\t21\t23\t42\t21\t53\t26\t50\t22\t25\t49\t43\t22\t47\t29\t28\t39\t43\t28\t42\t24\t24\t27\t21\t33\t31\t34\t43\t21\t43\t29\t30\t40\t41\t29\t21\t22\t25\t32\t40\t30\t28\t39\t28\t33\t22\t34\t39\t22\t28\t23\t24\t24\t23\t30\t28\t31\t26\t45\t26\t38\t46\t27\t26\t22\t29\t51\t22\t37\t31\t31\t33\t24\t22\t23\t28\t27\t21\t22\t27\t25\t35\t25\t35\t25\t39\t23\t59\t26\t21\t25\t21\t25\t30\t29\t21\t21\t37\t22\t26\t40\t36\t55\t26\t21\t26\t24\t42\t27\t33\t28\t58\t21\t23\t36\t45\t26\t29\t53\t24\t26\t24\t27\t24\t32\t24\t21\t31\t25\t52\t37\t52\t28\t35\t30\t34\t58\t30\t22\t22\t22\t27\t29\t28\t26\t24\t24\t41\t22\t42\t22\t24\t22\t32\t26\t23\t33\t27\t32\t31\t22\t25\t25\t41\t21\t43\t39\t37\t24\t22\t25\t22\t24\t23\t51\t21\t81\t28\t51\t25\t23\t27\t21\t33\t23\t43\t28\t22\t27\t21\t22\t36\t22\t28\t23\t26\t26\t46\t36\t21\t46\t22\t21\t32\t48\t24\t26\t22\t35\t22\t34\t39\t23\t25\t34\t31\t26\t42\t23\t31\t60\t35\t41\t22\t22\t29\t29\t25\t22\t22\t29\t21\t27\t26\t33\t21\t21\t22\t34\t22\t49\t28\t21\t21\t22\t26\t23\t22\t30\t21\t30\t28\t26\t37\t29\t23\t36\t31\t22\t23\t23\t53\t27\t28\t54\t45\t23\t24\t23\t40\t33\t55\t24\t25\t57\t36\t23\t37\t25\t25\t25\t45\t22\t21\t58\t24\t26\t26\t22\t24\t27\t24\t36\t23\t37\t31\r\n",
            "64\t74\t70\t64\t76\t62\t84\t78\t68\t86\t66\t70\t78\t68\t58\t78\t52\t58\t74\t88\t56\t64\t78\t60\t68\t72\t58\t74\t78\t62\t64\t72\t50\t76\t72\t64\t72\t68\t65\t70\t68\t60\t76\t70\t72\t58\t84\t48\t52\t64\t80\t70\t74\t76\t66\t70\t78\t76\t74\t52\t64\t30\t90\t48\t66\t82\t70\t78\t74\t62\t76\t72\t62\t70\t62\t58\t70\t72\t80\t106\t62\t60\t64\t68\t68\t88\t50\t82\t80\t44\t68\t82\t100\t68\t88\t66\t56\t74\t68\t86\t78\t72\t88\t90\t40\t70\t64\t90\t58\t68\t66\t72\t72\t70\t60\t60\t74\t58\t74\t88\t54\t64\t70\t72\t64\t66\t68\t74\t60\t58\t82\t68\t54\t60\t80\t68\t78\t74\t74\t80\t64\t62\t85\t64\t70\t76\t74\t82\t88\t60\t60\t60\t54\t64\t90\t50\t70\t76\t84\t72\t58\t90\t66\t82\t52\t76\t86\t60\t94\t82\t62\t64\t70\t66\t84\t72\t78\t70\t60\t110\t80\t58\t70\t62\t68\t30\t68\t86\t86\t72\t86\t90\t50\t54\t72\t78\t50\t76\t76\t64\t80\t65\t82\t72\t60\t50\t70\t84\t68\t76\t90\t86\t74\t44\t68\t80\t82\t74\t62\t60\t56\t74\t90\t66\t38\t72\t80\t80\t54\t66\t58\t80\t58\t92\t44\t62\t74\t82\t76\t76\t78\t90\t64\t68\t64\t106\t54\t88\t60\t50\t78\t58\t54\t64\t84\t74\t74\t62\t84\t70\t86\t60\t60\t98\t58\t74\t68\t86\t74\t86\t82\t78\t46\t74\t50\t68\t76\t62\t78\t64\t82\t58\t56\t70\t72\t78\t68\t48\t100\t80\t78\t74\t64\t50\t84\t78\t88\t66\t74\t88\t90\t70\t64\t64\t70\t70\t64\t80\t56\t66\t86\t88\t76\t68\t78\t62\t56\t84\t70\t46\t88\t66\t24\t60\t60\t56\t58\t52\t74\t60\t64\t64\t76\t72\t80\t62\t82\t76\t82\t56\t80\t70\t78\t88\t110\t70\t62\t88\t82\t88\t50\t72\t54\t68\t76\t70\t62\t70\t78\t52\t58\t102\t66\t62\t78\t85\t64\t66\t58\t80\t72\t74\t74\t70\t72\t74\r\n",
            "35.1\t30\t30.8\t34.9\t53.2\t25.1\t35\t34.6\t29.7\t45.5\t28.1\t31.6\t35.2\t31.9\t34\t46.7\t24.6\t27.7\t33.6\t43.3\t33.3\t33.2\t33.8\t37.2\t30.1\t25.8\t29.5\t29.9\t39\t22.1\t33.6\t30.1\t33.9\t36.5\t25.6\t34\t36.9\t30\t36.8\t35.4\t30.2\t28.8\t32.9\t24.3\t33.6\t32.7\t30.7\t40.5\t36.2\t23.7\t46.2\t42.9\t33.2\t31.2\t34.3\t33.1\t32\t31.6\t30.4\t32.5\t40.6\t43.3\t49.7\t42.1\t38.1\t38.4\t39.4\t29.6\t37.4\t19.5\t31.6\t34.4\t36.6\t29.7\t27.2\t25.4\t33.1\t37.1\t44.2\t35.5\t32.8\t36.6\t21.2\t29.3\t26\t30.3\t31\t32.8\t19.4\t35.5\t33.6\t35\t57.3\t25.5\t37.7\t38.1\t24.7\t39.4\t31.6\t39.1\t34.5\t30.8\t39.3\t25.2\t43.1\t36.7\t30.5\t30.4\t26.4\t38.5\t41.3\t26.2\t33.9\t31.1\t30.9\t34.6\t29\t34.9\t46.3\t34.5\t34\t26.4\t35.3\t25.3\t29.7\t30.8\t30.9\t29.3\t34.7\t27.8\t38.2\t37.6\t25.6\t43.5\t19.3\t33.1\t43.3\t30.5\t37.2\t33.2\t34.1\t34\t28.9\t34.8\t34.2\t39.7\t26\t25.2\t32.4\t27.5\t33.8\t24\t37.8\t41.5\t52.3\t33.3\t20.4\t23.2\t42.4\t27.6\t34.3\t36.5\t19.6\t35.8\t38.7\t35.9\t30.1\t30.1\t40.6\t24.7\t35.8\t33.2\t25\t24.4\t39.4\t38.6\t33.2\t25.5\t28.7\t67.1\t37.9\t32.9\t25.1\t21.8\t24.8\t55\t42.3\t34.3\t29.3\t36.1\t38.4\t33.7\t30.4\t25.2\t32.7\t30.9\t24.2\t38.2\t43.6\t31.2\t36.5\t42.6\t41.5\t33.3\t26.9\t25.9\t43.5\t45.8\t39.9\t28.7\t34.5\t33.3\t19.5\t24\t32.9\t32\t32\t34.9\t25.3\t23.9\t29\t26.6\t28.4\t32.9\t23.1\t26.6\t24.4\t38.9\t26.1\t34.7\t28.5\t45.2\t29.5\t36.4\t30.8\t20.1\t23.4\t34.2\t40.9\t27.9\t40\t39.5\t36.8\t37.7\t35.8\t37.6\t30.5\t36.5\t35.5\t37.8\t59.4\t28.4\t22.3\t27.8\t37.6\t26.2\t25.9\t35.5\t35.9\t40.5\t35.1\t33.8\t34.6\t32\t33.3\t33.6\t42.4\t27.5\t32.4\t27.4\t32\t42.9\t28.7\t34.1\t28.7\t21.1\t47.9\t32\t29.3\t18.2\t46.1\t24.8\t28.7\t34.6\t20.8\t39.4\t38.5\t20.4\t43.4\t25.4\t28.4\t25.9\t38\t29.5\t38.7\t37\t45.3\t32\t24.1\t46.8\t19.6\t35.5\t33.3\t44.6\t25.9\t28\t31.2\t31.6\t24.2\t23.2\t45.6\t36.9\t28.4\t34.1\t34.2\t25.2\t21.8\t35.7\t35.4\t34.4\t38.5\t41.3\t27.8\t25.4\t29.8\t20.8\t24.2\t27.8\t39.4\t28.6\t34.5\t36.9\t35.9\t31.3\t33.7\t29.9\t34.2\t23.8\t27.5\t25.2\t36.3\t30.5\t46.1\t34.5\t45.4\t28.9\t24\t44.5\t40.6\t38.2\t27.1\t37.7\t30.9\t30.5\t37.5\t36.4\t22.9\t30.8\t36.1\t28.5\t31.6\t32.8\t32.2\t40.7\t46.5\t37.4\t28.6\t23.6\t21.8\t34.8\t32.4\t26.3\t25.9\t39.1\t22.1\t29.9\n",
            "61\t40\t50\t59.5\t81\t45\t68\t43.5\t37\t51\t44.5\t81.5\t75\t42\t49\t40.5\t49.5\t63.5\t53.5\t90.5\t38.5\t58.5\t86.5\t43.5\t90.5\t83\t72\t52\t60.5\t69.5\t52\t40.5\t93.5\t98\t78.5\t90\t52.5\t62.5\t41.5\t67\t43\t71\t50.5\t62.5\t61.5\t43.5\t63\t64\t61\t65.5\t67\t60\t64.5\t44.5\t60.5\t61.5\t44\t79\t44.5\t54\t51\t51.5\t61\t61.5\t57\t86.5\t53\t63\t68\t46\t47\t56\t53.5\t86.5\t45\t70.5\t45.5\t55.5\t57\t34\t77\t49.5\t41\t74.5\t47\t72.5\t39\t82\t51.5\t59.5\t82.5\t47.5\t61.5\t80.5\t45\t57.5\t48\t50\t50\t58.5\t51\t53.5\t63\t58.5\t68.5\t98.5\t53\t71\t67\t64.5\t43\t60.5\t72\t62.5\t74\t69\t44\t52.5\t40.5\t58.5\t49.5\t64.5\t37\t50\t37.5\t58.5\t95.5\t77\t49\t42.5\t42\t43.5\t49.5\t39.5\t49.5\t65.5\t64\t60\t51\t62\t90.5\t77.5\t73\t54.5\t53\t60\t68\t49\t66.5\t64.5\t62.5\t51.5\t50\t52.5\t82.5\t62.5\t49.5\t49.5\t71.5\t51.5\t41.5\t90\t47.5\t38.5\t77.5\t64.5\t71.5\t94.5\t67.5\t71\t54.5\t48\t34\t44\t79\t49.5\t35.5\t62\t46.5\t64.5\t72.5\t87\t97.5\t49.5\t68.5\t44\t67.5\t78\t51\t54\t56\t88\t42\t45.5\t89.5\t77\t50.5\t73\t93.5\t79\t47.5\t70\t76\t85.5\t49.5\t96.5\t47\t59\t45.5\t62\t93\t88\t50\t54\t62\t61.5\t72\t73.5\t54\t47.5\t53\t77.5\t55.5\t50\t54.5\t40.5\t45\t60\t47.5\t75\t54.5\t58.5\t55.5\t64.5\t51\t34\t83.5\t40\t48.5\t54.5\t90.5\t42\t48.5\t93.5\t42\t83.5\t80\t64\t54\t89.5\t90\t44\t59.5\t52\t74\t71.5\t67\t75.5\t90.5\t50\t64.5\t58.5\t88.5\t64\t59\t48\t86\t40.5\t55\t63\t94\t75.5\t69.5\t61.5\t46.5\t48\t82.5\t46\t41.5\t48.5\t72\t44\t63\t57.5\t60\t56\t50\t35.5\t46.5\t39.5\t65\t63\t46.5\t56.5\t77.5\t92\t59.5\t50\t70\t50\t64.5\t79\t47\t47.5\t65\t73\t94.5\t69.5\t28\t48.5\t59.5\t39\t55\t56\t76\t54\t62\t86.5\t62\t63.5\t63\t99\t44.5\t54.5\t61\t48\t50.5\t37\t78.5\t65\t85\t42\t61\t77\t52.5\t44\t56\t57\t64\t54.5\t63.5\t98.5\t77\t63.5\t85.5\t62.5\t55.5\t87\t76.5\t84\t59.5\t51.5\t53\t64\t98\t93.5\t53.5\t52.5\t58\t41\t72\t66.5\t41.5\t69.5\t86.5\t47.5\t69.5\t50\t50.5\t56\t64\t58\t47.5\t60.5\t58\t84.5\n",
            "positive\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tpositive\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tpositive\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\tpositive\tpositive\tpositive\tnegative\tnegative\tpositive\tpositive\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tpositive\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tpositive\tpositive\tpositive\tpositive\tnegative\tnegative\tpositive\tnegative\tpositive\tpositive\tpositive\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tpositive\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tpositive\tpositive\tnegative\tpositive\tnegative\tpositive\tpositive\tnegative\tnegative\tpositive\tpositive\tpositive\tpositive\tnegative\tnegative\tnegative\tpositive\tpositive\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\tnegative\tnegative\tnegative\tnegative\tpositive\n",
            "1\t1\t0\t0\t0\t1\t5\t1\t3\t2\t1\t3\t7\t3\t6\t7\t2\t2\t2\t0\t1\t4\t3\t1\t8\t5\t4\t6\t1\t0\t0\t2\t7\t1\t1\t3\t5\t6\t2\t6\t5\t7\t10\t1\t6\t2\t0\t1\t2\t1\t6\t3\t2\t1\t0\t9\t1\t3\t3\t2\t0\t1\t1\t2\t1\t3\t0\t5\t1\t1\t2\t1\t0\t4\t1\t2\t4\t4\t0\t10\t4\t2\t1\t1\t2\t9\t3\t1\t1\t1\t6\t1\t3\t10\t4\t3\t3\t8\t3\t5\t0\t1\t3\t2\t0\t4\t2\t7\t0\t7\t1\t5\t6\t10\t4\t0\t2\t2\t1\t1\t5\t3\t8\t1\t2\t0\t3\t6\t2\t4\t0\t1\t3\t1\t3\t4\t2\t0\t7\t3\t1\t8\t4\t4\t1\t2\t7\t0\t7\t4\t2\t4\t2\t0\t0\t1\t2\t4\t1\t3\t3\t0\t1\t5\t2\t10\t1\t1\t0\t2\t5\t1\t2\t5\t5\t1\t1\t7\t0\t0\t9\t3\t7\t3\t0\t1\t0\t9\t0\t5\t2\t8\t2\t1\t8\t9\t1\t2\t5\t3\t0\t0\t0\t3\t6\t1\t0\t0\t0\t8\t8\t3\t1\t6\t2\t4\t5\t4\t2\t1\t2\t2\t3\t2\t1\t1\t2\t1\t2\t7\t1\t0\t3\t3\t3\t2\t1\t3\t7\t8\t1\t4\t0\t7\t0\t8\t7\t1\t1\t0\t0\t2\t1\t0\t10\t1\t9\t6\t7\t2\t4\t1\t0\t1\t1\t5\t1\t3\t2\t0\t0\t8\t1\t5\t6\t2\t0\t6\t7\t1\t1\t3\t1\t1\t9\t2\t2\t1\t0\t1\t3\t8\t2\t3\t5\t4\t1\t1\t1\t0\t6\t3\t7\t0\t1\t2\t5\t5\t2\t1\t1\t0\t4\t2\t9\t2\t0\t3\t9\t2\t8\t0\t1\t1\t2\t4\t2\t0\t2\t1\t3\t1\t2\t4\t2\t1\t9\t7\t1\t1\t0\t2\t6\t4\t9\t4\t1\t2\t1\t7\t6\t6\t3\t0\t8\t3\t3\t6\t1\t2\t2\t1\t2\t1\t0\t0\t5\t1\t2\t1\t3\t3\t1\t2\t4\t3\n",
            "156\t60\t50\t92\t100\t59\t88\t32\t45\t120\t94\t105\t126\t106\t190\t48\t94\t275\t100\t510\t56\t120\t185\t75\t495\t175\t140\t156\t74\t210\t64\t76\t392\t249\t168\t70\t325\t120\t66\t130\t71\t190\t180\t110\t230\t52\t215\t194\t158\t415\t370\t135\t205\t37\t165\t94\t76\t245\t85\t63\t78\t83\t220\t165\t200\t465\t148\t22\t204\t41\t66\t176\t74\t168\t43\t128\t88\t207\t285\t49\t284\t160\t95\t127\t76\t165\t88\t67\t82\t63\t168\t180\t240\t132\t54\t140\t115\t215\t81\t105\t90\t82\t235\t71\t168\t744\t119\t480\t291\t125\t65\t112\t228\t115\t318\t167\t53\t94\t57\t145\t83\t115\t49\t70\t55\t188\t130\t193\t120\t49\t125\t77\t86\t48\t64\t166\t182\t63\t105\t130\t180\t495\t100\t99\t135\t105\t135\t84\t155\t231\t140\t192\t105\t142\t680\t167\t44\t51\t310\t152\t18\t90\t38\t42\t540\t122\t330\t846\t145\t64\t129\t87\t66\t23\t210\t18\t45\t215\t92\t130\t130\t194\t145\t74\t148\t99\t250\t155\t105\t75\t160\t300\t76\t100\t130\t100\t36\t194\t207\t387\t92\t130\t272\t135\t54\t375\t115\t230\t210\t600\t225\t156\t46\t130\t205\t176\t285\t293\t278\t58\t165\t96\t78\t90\t120\t40\t55\t200\t88\t342\t116\t53\t44\t155\t94\t15\t144\t70\t91\t114\t293\t56\t100\t304\t66\t231\t175\t110\t178\t159\t14\t16\t50\t116\t237\t61\t60\t120\t192\t57\t270\t106\t478\t58\t94\t67\t579\t66\t125\t120\t185\t210\t83\t77\t64\t49\t255\t126\t71\t82\t180\t54\t152\t96\t56\t140\t71\t76\t72\t37\t79\t75\t160\t85\t545\t277\t170\t196\t180\t110\t326\t328\t79\t105\t105\t360\t325\t160\t45\t140\t220\t40\t100\t94\t171\t56\t105\t474\t402\t335\t108\t274\t25\t182\t106\t49\t265\t36\t440\t170\t225\t115\t200\t126\t191\t44\t175\t110\t183\t135\t210\t543\t140\t155\t240\t122\t182\t120\t485\t321\t176\t190\t158\t180\t280\t200\t48\t68\t180\t115\t135\t140\t50\t480\t265\t36\t140\t56\t90\t132\t190\t105\t73\t95\t87\t125\n",
            "0.692\t0.527\t0.597\t0.725\t0.759\t1.268\t0.286\t0.101\t0.293\t0.127\t0.167\t0.268\t0.692\t0.591\t0.43\t0.261\t0.637\t1.6\t0.404\t0.222\t1.251\t0.23\t0.97\t0.509\t0.615\t0.587\t0.287\t0.722\t0.261\t0.207\t0.51\t0.547\t0.826\t0.875\t0.123\t0.271\t0.159\t0.464\t0.629\t0.542\t0.364\t0.687\t0.171\t0.221\t0.733\t0.166\t0.52\t0.613\t0.816\t0.389\t0.238\t0.452\t0.591\t0.192\t0.203\t0.374\t0.365\t0.851\t0.551\t0.318\t0.496\t0.183\t0.325\t0.52\t0.289\t2.137\t0.605\t0.439\t0.399\t0.482\t0.649\t0.528\t0.757\t0.361\t0.58\t0.699\t0.446\t1.39\t0.167\t0.285\t0.237\t0.453\t0.415\t0.349\t0.561\t0.771\t0.248\t0.341\t0.491\t0.28\t0.631\t0.233\t0.88\t0.326\t0.362\t0.15\t0.944\t0.661\t0.949\t0.251\t0.238\t0.821\t0.704\t0.313\t2.288\t2.329\t1.4\t0.128\t0.352\t0.439\t0.917\t0.245\t0.255\t0.205\t0.15\t0.534\t0.229\t0.225\t1.096\t0.403\t0.499\t0.219\t0.705\t0.658\t0.37\t0.493\t0.299\t0.839\t0.198\t0.306\t0.233\t0.401\t0.154\t0.678\t0.284\t0.16\t1.224\t0.285\t0.204\t0.305\t0.328\t0.543\t0.189\t0.905\t0.142\t0.215\t0.647\t0.299\t0.262\t0.527\t0.088\t0.966\t0.498\t0.173\t0.427\t0.962\t0.235\t0.223\t1.076\t0.73\t0.336\t0.314\t0.334\t0.156\t0.24\t0.28\t0.892\t0.398\t0.284\t0.761\t0.514\t0.289\t0.187\t0.342\t0.395\t0.412\t0.422\t0.161\t0.532\t0.319\t0.637\t0.593\t0.163\t0.279\t0.143\t0.496\t0.365\t1.189\t0.695\t0.263\t0.246\t0.467\t0.968\t0.234\t0.719\t0.164\t0.526\t0.329\t1.034\t0.295\t0.33\t0.431\t0.27\t0.199\t0.497\t0.655\t0.347\t0.551\t0.381\t0.687\t0.423\t1.154\t0.149\t0.813\t0.875\t0.443\t0.452\t0.385\t0.881\t0.26\t0.426\t0.433\t0.495\t0.867\t0.407\t0.283\t0.249\t1.162\t0.748\t0.718\t0.219\t0.089\t0.43\t0.968\t0.4\t0.257\t0.447\t1.292\t0.871\t0.64\t1.258\t0.159\t0.6\t0.254\t0.545\t0.165\t0.588\t1.057\t0.415\t0.455\t2.42\t0.766\t0.205\t0.454\t1.001\t0.256\t0.46\t0.692\t0.586\t0.677\t0.231\t0.466\t1.072\t1.321\t0.261\t0.997\t0.702\t0.306\t0.698\t0.515\t0.682\t0.516\t0.654\t0.269\t0.356\t0.647\t0.259\t0.085\t0.767\t0.299\t0.335\t0.267\t0.801\t0.529\t0.733\t0.175\t0.324\t0.323\t1.021\t0.583\t0.323\t0.162\t0.674\t0.626\t0.619\t0.264\t0.507\t0.444\t0.828\t0.962\t0.582\t0.344\t0.738\t0.366\t0.472\t0.337\t0.583\t0.361\t0.332\t0.487\t0.808\t0.434\t0.118\t0.315\t0.893\t0.128\t0.452\t0.258\t0.282\t0.176\t0.349\t0.502\t0.559\t0.947\t0.717\t0.34\t0.614\t0.269\t0.134\t0.692\t0.356\t0.471\t0.483\t0.338\t0.711\t0.422\t0.26\t0.466\t0.115\t0.833\t0.804\t0.158\t0.571\t0.598\t0.721\t1.144\t0.138\t0.646\t0.687\t0.787\t1.318\t0.324\t0.292\t1.391\t0.605\t0.408\t0.678\t0.122\t0.496\t1.699\t0.422\t0.234\t0.497\t0.536\t1.159\t0.247\t0.411\t0.666\t0.155\t0.217\t0.549\t0.107\t0.673\t0.886\t0.463\t0.268\n",
            "32\t11\t26\t18\t56\t18\t41\t27\t28\t36\t23\t18\t29\t30\t33\t40\t15\t24\t30\t44\t30\t27\t39\t37\t36\t19\t28\t18\t39\t17\t37\t15\t33\t36\t21\t25\t29\t30\t28\t23\t28\t33\t48\t24\t45\t16\t29\t45\t43\t14\t37\t30\t26\t34\t30\t44\t29\t36\t16\t26\t46\t38\t51\t32\t36\t48\t37\t27\t50\t25\t18\t30\t30\t14\t12\t34\t32\t47\t34\t23\t31\t17\t13\t29\t18\t34\t32\t43\t11\t47\t26\t25\t35\t23\t47\t39\t34\t40\t23\t30\t40\t30\t41\t19\t35\t39\t35\t24\t20\t49\t52\t23\t27\t26\t27\t35\t19\t40\t41\t24\t28\t29\t40\t12\t24\t31\t15\t32\t17\t22\t31\t34\t19\t42\t11\t21\t37\t18\t40\t33\t30\t26\t27\t44\t28\t37\t26\t15\t15\t12\t20\t33\t28\t41\t33\t40\t16\t15\t23\t30\t31\t26\t13\t41\t27\t28\t30\t23\t46\t18\t41\t27\t32\t21\t41\t30\t50\t33\t25\t46\t46\t22\t33\t19\t14\t42\t42\t28\t17\t43\t42\t34\t23\t25\t42\t30\t15\t35\t27\t13\t45\t26\t39\t33\t19\t16\t27\t47\t32\t24\t35\t27\t12\t20\t28\t15\t26\t25\t10\t18\t27\t17\t12\t20\t18\t18\t14\t48\t14\t42\t18\t31\t31\t49\t20\t13\t17\t31\t32\t39\t42\t23\t36\t39\t22\t46\t32\t39\t46\t36\t63\t26\t13\t23\t48\t22\t33\t31\t21\t52\t20\t23\t29\t41\t36\t18\t49\t16\t29\t27\t14\t32\t19\t40\t30\t13\t43\t32\t26\t19\t46\t11\t29\t30\t22\t50\t25\t18\t39\t25\t23\t38\t32\t10\t44\t39\t41\t29\t26\t60\t7\t30\t25\t39\t13\t38\t33\t35\t28\t15\t39\t29\t20\t22\t34\t32\t13\t33\t33\t21\t36\t32\t19\t8\t18\t17\t17\t10\t35\t23\t37\t23\t27\t29\t45\t24\t32\t17\t17\t21\t37\t45\t41\t11\t24\t18\t13\t37\t42\t42\t22\t32\t21\t19\t29\t22\t13\t32\t29\t22\t33\t28\t23\t41\t32\t25\t35\t15\t35\t45\t25\t15\t21\t32\t12\t19\n",
            "12.7\t0\t22.6\t1.8\t3.6\t16.8\t34.1\t31.4\t1.8\t30.6\t31.2\t16.6\t14.5\t9.5\t14.3\t17.3\t17.3\t16.4\t7.9\t16.7\t11.5\t10.7\t2.4\t25.9\t12.1\t10.5\t24.4\t29.4\t19\t0\t24.5\t13.2\t8.6\t17.6\t14.9\t2.6\t34.2\t4.9\t21.1\t20.1\t25.9\t8.1\t33.7\t4.6\t23.5\t11.9\t29.7\t14.4\t17.2\t2.9\t0.9\t32.2\t21.4\t24\t5.7\t24\t10.7\t21.6\t14.9\t34.8\t18.7\t16.1\t2.8\t19.6\t16.3\t28.5\t36.2\t25.3\t4.8\t27.4\t21.1\t6.9\t19.2\t23.5\t0.5\t6.5\t3\t5.2\t27.4\t5.5\t32.8\t34.4\t30.4\t7.7\t13.3\t25.9\t16.3\t1.2\t16.1\t35.8\t5.7\t31.7\t24\t6.5\t27.4\t26.4\t36\t1.2\t28.9\t26.2\t23.5\t5\t18.5\t13.1\t31.9\t34.4\t27.7\t10.5\t13.8\t22.6\t23.2\t30.3\t6\t10.7\t10.4\t35.7\t5.2\t13.9\t4\t5.5\t4\t35.6\t30.4\t8.9\t24.3\t31.1\t1.2\t32.6\t32.8\t2.9\t17.4\t25.6\t8.5\t1.3\t14.7\t13.1\t4.3\t8\t10.1\t2.9\t0.4\t12.7\t23.1\t10.8\t7.6\t30.7\t30.5\t15.5\t24.5\t19.9\t27\t16.1\t27.8\t3.4\t29\t19.9\t12.2\t30.5\t10.2\t12.5\t15.9\t24.1\t5\t8.6\t10.7\t2.7\t17.7\t5\t9.3\t35.5\t20.7\t13\t13.8\t35.7\t0.5\t1.4\t15.1\t22.4\t31.8\t35.5\t18.6\t29.5\t9.1\t21.7\t2.7\t22.8\t15.4\t36.3\t8.2\t32.4\t33.3\t6.6\t34.2\t7\t33.1\t3.7\t30.7\t35.5\t1.2\t9.8\t17.4\t7.3\t18.9\t6.6\t29.7\t31\t3.5\t5.3\t3.6\t19.3\t18.6\t33.4\t25.8\t5.1\t12.8\t32.3\t20.6\t26.9\t3.8\t25.9\t12.9\t30.4\t26.1\t22.7\t14.2\t14.9\t29.3\t8.8\t34.1\t4.4\t23.9\t10.8\t15\t0.6\t0.1\t15.9\t28.6\t25.2\t9.2\t15.6\t23.9\t35.7\t6.7\t7.3\t32.2\t26.3\t18.3\t30.4\t9.2\t8.3\t17.8\t14\t29.4\t3.3\t5.4\t10.1\t9.5\t24.4\t35.5\t0.5\t26.1\t27.8\t13.3\t1.9\t36.3\t30.4\t29.2\t9.3\t6.4\t2.1\t20.4\t4.8\t26.4\t5.7\t32.7\t0.4\t21\t2.3\t20.6\t33.2\t3.3\t22.3\t32.3\t21.9\t22.5\t21.2\t25.9\t6.7\t17.3\t19.2\t22.6\t11.4\t22.4\t9.2\t4.3\t9.9\t21.3\t17\t32.4\t7.3\t36.5\t10.3\t35.1\t33.5\t7.8\t16.3\t31.5\t22.7\t26.1\t30.5\t6\t4.9\t25.8\t26.8\t7.5\t19\t26.4\t36.2\t26.7\t20.3\t8.1\t7\t20.4\t21.3\t28.5\t22.9\t29.6\t25.5\t17.2\t27.1\t18.3\t4.7\t11.9\t21.5\t3.3\t33.5\t2.8\t7.6\t6.3\t25.8\t28\t15.9\t1.9\t13.4\t24\t31.7\t35.4\t20\t20.2\t31.6\t27.7\t18.7\t11.8\t26.4\t1.2\t6.7\t13.8\t1.3\t29.9\t2.7\t4.7\t35.2\t16\t27.7\t12\t10.8\t23.1\t24\t31.5\t34.6\t24.1\t23\t31.6\t31.3\t0.5\t35.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gSxQn7Qz4T13",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "metadata": {
        "id": "P0wq-zwm1k7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ka3S3uiYbvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "Y86H9VtoXbiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Data in the dataset is seperated by tab. Each row represents an attribute and columns represent each individual patients. \n",
        "\n",
        "* In order to load the data into pandas dataframe, the file should be read using read_csv and use the seperator as tab ('\\t'). A transpose of the dataframe is required to bring the data into traditional format i.e. features in columns and observations (patients) in rows. \n",
        "\n",
        "* After getting the data in desired format, column names are added to give more sense and completeness to the dataframe.\n",
        "\n",
        "* Data and Response used to train and test the models should be in numbers as numpy arrays. So Autoimmune_Disease column needs to be coverted to 0 and 1 representing negative and positive respectively. "
      ]
    },
    {
      "metadata": {
        "id": "PMBsuaR79Pxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2012
        },
        "outputId": "a286b237-7459-404a-c9b8-651a65c11bd0"
      },
      "cell_type": "code",
      "source": [
        "fields = ['Age', 'Blood_Pressure', 'BMI', 'Plasma_level', 'Autoimmune_Disease', 'Adverse_events', 'Drug_in_serum', 'Liver_function', 'Activity_test', 'Secondary_test']\n",
        "autoimmune_data = pd.read_csv(r'/content/gdrive/My Drive/GYE06/CT475_ML/autoimmune.txt',\n",
        "                 sep='\\t',\n",
        "                 header=None\n",
        "                )\n",
        "autoimmune_data = autoimmune_data.transpose()\n",
        "autoimmune_data.columns = fields\n",
        "autoimmune_data['Autoimmune_Disease'] = autoimmune_data['Autoimmune_Disease'].map({'negative':0, 'positive':1})\n",
        "autoimmune_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Blood_Pressure</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Plasma_level</th>\n",
              "      <th>Autoimmune_Disease</th>\n",
              "      <th>Adverse_events</th>\n",
              "      <th>Drug_in_serum</th>\n",
              "      <th>Liver_function</th>\n",
              "      <th>Activity_test</th>\n",
              "      <th>Secondary_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>35.1</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>0.692</td>\n",
              "      <td>32</td>\n",
              "      <td>12.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>74</td>\n",
              "      <td>30</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0.527</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>70</td>\n",
              "      <td>30.8</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.597</td>\n",
              "      <td>26</td>\n",
              "      <td>22.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>64</td>\n",
              "      <td>34.9</td>\n",
              "      <td>59.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "      <td>0.725</td>\n",
              "      <td>18</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>76</td>\n",
              "      <td>53.2</td>\n",
              "      <td>81</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0.759</td>\n",
              "      <td>56</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>62</td>\n",
              "      <td>25.1</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>1.268</td>\n",
              "      <td>18</td>\n",
              "      <td>16.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>35</td>\n",
              "      <td>84</td>\n",
              "      <td>35</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>88</td>\n",
              "      <td>0.286</td>\n",
              "      <td>41</td>\n",
              "      <td>34.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>22</td>\n",
              "      <td>78</td>\n",
              "      <td>34.6</td>\n",
              "      <td>43.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0.101</td>\n",
              "      <td>27</td>\n",
              "      <td>31.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>23</td>\n",
              "      <td>68</td>\n",
              "      <td>29.7</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>45</td>\n",
              "      <td>0.293</td>\n",
              "      <td>28</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>23</td>\n",
              "      <td>86</td>\n",
              "      <td>45.5</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0.127</td>\n",
              "      <td>36</td>\n",
              "      <td>30.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>21</td>\n",
              "      <td>66</td>\n",
              "      <td>28.1</td>\n",
              "      <td>44.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>94</td>\n",
              "      <td>0.167</td>\n",
              "      <td>23</td>\n",
              "      <td>31.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>28</td>\n",
              "      <td>70</td>\n",
              "      <td>31.6</td>\n",
              "      <td>81.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>105</td>\n",
              "      <td>0.268</td>\n",
              "      <td>18</td>\n",
              "      <td>16.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>54</td>\n",
              "      <td>78</td>\n",
              "      <td>35.2</td>\n",
              "      <td>75</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>126</td>\n",
              "      <td>0.692</td>\n",
              "      <td>29</td>\n",
              "      <td>14.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>25</td>\n",
              "      <td>68</td>\n",
              "      <td>31.9</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>106</td>\n",
              "      <td>0.591</td>\n",
              "      <td>30</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>43</td>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>0.43</td>\n",
              "      <td>33</td>\n",
              "      <td>14.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>42</td>\n",
              "      <td>78</td>\n",
              "      <td>46.7</td>\n",
              "      <td>40.5</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>48</td>\n",
              "      <td>0.261</td>\n",
              "      <td>40</td>\n",
              "      <td>17.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>21</td>\n",
              "      <td>52</td>\n",
              "      <td>24.6</td>\n",
              "      <td>49.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>0.637</td>\n",
              "      <td>15</td>\n",
              "      <td>17.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25</td>\n",
              "      <td>58</td>\n",
              "      <td>27.7</td>\n",
              "      <td>63.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>275</td>\n",
              "      <td>1.6</td>\n",
              "      <td>24</td>\n",
              "      <td>16.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>23</td>\n",
              "      <td>74</td>\n",
              "      <td>33.6</td>\n",
              "      <td>53.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>0.404</td>\n",
              "      <td>30</td>\n",
              "      <td>7.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>26</td>\n",
              "      <td>88</td>\n",
              "      <td>43.3</td>\n",
              "      <td>90.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>0.222</td>\n",
              "      <td>44</td>\n",
              "      <td>16.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>24</td>\n",
              "      <td>56</td>\n",
              "      <td>33.3</td>\n",
              "      <td>38.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1.251</td>\n",
              "      <td>30</td>\n",
              "      <td>11.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>24</td>\n",
              "      <td>64</td>\n",
              "      <td>33.2</td>\n",
              "      <td>58.5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>0.23</td>\n",
              "      <td>27</td>\n",
              "      <td>10.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>31</td>\n",
              "      <td>78</td>\n",
              "      <td>33.8</td>\n",
              "      <td>86.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>185</td>\n",
              "      <td>0.97</td>\n",
              "      <td>39</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>60</td>\n",
              "      <td>37.2</td>\n",
              "      <td>43.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>0.509</td>\n",
              "      <td>37</td>\n",
              "      <td>25.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>30.1</td>\n",
              "      <td>90.5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>495</td>\n",
              "      <td>0.615</td>\n",
              "      <td>36</td>\n",
              "      <td>12.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>51</td>\n",
              "      <td>72</td>\n",
              "      <td>25.8</td>\n",
              "      <td>83</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>175</td>\n",
              "      <td>0.587</td>\n",
              "      <td>19</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>37</td>\n",
              "      <td>58</td>\n",
              "      <td>29.5</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>140</td>\n",
              "      <td>0.287</td>\n",
              "      <td>28</td>\n",
              "      <td>24.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>41</td>\n",
              "      <td>74</td>\n",
              "      <td>29.9</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>156</td>\n",
              "      <td>0.722</td>\n",
              "      <td>18</td>\n",
              "      <td>29.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>78</td>\n",
              "      <td>39</td>\n",
              "      <td>60.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>0.261</td>\n",
              "      <td>39</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>21</td>\n",
              "      <td>62</td>\n",
              "      <td>22.1</td>\n",
              "      <td>69.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210</td>\n",
              "      <td>0.207</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>23</td>\n",
              "      <td>62</td>\n",
              "      <td>24</td>\n",
              "      <td>55.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>182</td>\n",
              "      <td>0.138</td>\n",
              "      <td>13</td>\n",
              "      <td>35.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>24</td>\n",
              "      <td>88</td>\n",
              "      <td>44.5</td>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0.646</td>\n",
              "      <td>37</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>23</td>\n",
              "      <td>82</td>\n",
              "      <td>40.6</td>\n",
              "      <td>76.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>485</td>\n",
              "      <td>0.687</td>\n",
              "      <td>42</td>\n",
              "      <td>20.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>40</td>\n",
              "      <td>88</td>\n",
              "      <td>38.2</td>\n",
              "      <td>84</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>321</td>\n",
              "      <td>0.787</td>\n",
              "      <td>42</td>\n",
              "      <td>31.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>33</td>\n",
              "      <td>50</td>\n",
              "      <td>27.1</td>\n",
              "      <td>59.5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>176</td>\n",
              "      <td>1.318</td>\n",
              "      <td>22</td>\n",
              "      <td>27.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>55</td>\n",
              "      <td>72</td>\n",
              "      <td>37.7</td>\n",
              "      <td>51.5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>190</td>\n",
              "      <td>0.324</td>\n",
              "      <td>32</td>\n",
              "      <td>18.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>30.9</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>158</td>\n",
              "      <td>0.292</td>\n",
              "      <td>21</td>\n",
              "      <td>11.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>25</td>\n",
              "      <td>68</td>\n",
              "      <td>30.5</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>180</td>\n",
              "      <td>1.391</td>\n",
              "      <td>19</td>\n",
              "      <td>26.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>57</td>\n",
              "      <td>76</td>\n",
              "      <td>37.5</td>\n",
              "      <td>98</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>280</td>\n",
              "      <td>0.605</td>\n",
              "      <td>29</td>\n",
              "      <td>1.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>36</td>\n",
              "      <td>70</td>\n",
              "      <td>36.4</td>\n",
              "      <td>93.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>200</td>\n",
              "      <td>0.408</td>\n",
              "      <td>22</td>\n",
              "      <td>6.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>23</td>\n",
              "      <td>62</td>\n",
              "      <td>22.9</td>\n",
              "      <td>53.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>48</td>\n",
              "      <td>0.678</td>\n",
              "      <td>13</td>\n",
              "      <td>13.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>37</td>\n",
              "      <td>70</td>\n",
              "      <td>30.8</td>\n",
              "      <td>52.5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>68</td>\n",
              "      <td>0.122</td>\n",
              "      <td>32</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>25</td>\n",
              "      <td>78</td>\n",
              "      <td>36.1</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>180</td>\n",
              "      <td>0.496</td>\n",
              "      <td>29</td>\n",
              "      <td>29.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>25</td>\n",
              "      <td>52</td>\n",
              "      <td>28.5</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>115</td>\n",
              "      <td>1.699</td>\n",
              "      <td>22</td>\n",
              "      <td>2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>25</td>\n",
              "      <td>58</td>\n",
              "      <td>31.6</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>135</td>\n",
              "      <td>0.422</td>\n",
              "      <td>33</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>45</td>\n",
              "      <td>102</td>\n",
              "      <td>32.8</td>\n",
              "      <td>66.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>0.234</td>\n",
              "      <td>28</td>\n",
              "      <td>35.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>22</td>\n",
              "      <td>66</td>\n",
              "      <td>32.2</td>\n",
              "      <td>41.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>0.497</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>21</td>\n",
              "      <td>62</td>\n",
              "      <td>40.7</td>\n",
              "      <td>69.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>480</td>\n",
              "      <td>0.536</td>\n",
              "      <td>41</td>\n",
              "      <td>27.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>58</td>\n",
              "      <td>78</td>\n",
              "      <td>46.5</td>\n",
              "      <td>86.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>265</td>\n",
              "      <td>1.159</td>\n",
              "      <td>32</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>24</td>\n",
              "      <td>85</td>\n",
              "      <td>37.4</td>\n",
              "      <td>47.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0.247</td>\n",
              "      <td>25</td>\n",
              "      <td>10.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>26</td>\n",
              "      <td>64</td>\n",
              "      <td>28.6</td>\n",
              "      <td>69.5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>140</td>\n",
              "      <td>0.411</td>\n",
              "      <td>35</td>\n",
              "      <td>23.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>26</td>\n",
              "      <td>66</td>\n",
              "      <td>23.6</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>0.666</td>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>22</td>\n",
              "      <td>58</td>\n",
              "      <td>21.8</td>\n",
              "      <td>50.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>90</td>\n",
              "      <td>0.155</td>\n",
              "      <td>35</td>\n",
              "      <td>31.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>24</td>\n",
              "      <td>80</td>\n",
              "      <td>34.8</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0.217</td>\n",
              "      <td>45</td>\n",
              "      <td>34.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>27</td>\n",
              "      <td>72</td>\n",
              "      <td>32.4</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>190</td>\n",
              "      <td>0.549</td>\n",
              "      <td>25</td>\n",
              "      <td>24.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>24</td>\n",
              "      <td>74</td>\n",
              "      <td>26.3</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>105</td>\n",
              "      <td>0.107</td>\n",
              "      <td>15</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>36</td>\n",
              "      <td>74</td>\n",
              "      <td>25.9</td>\n",
              "      <td>47.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>0.673</td>\n",
              "      <td>21</td>\n",
              "      <td>31.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>23</td>\n",
              "      <td>70</td>\n",
              "      <td>39.1</td>\n",
              "      <td>60.5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>95</td>\n",
              "      <td>0.886</td>\n",
              "      <td>32</td>\n",
              "      <td>31.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>37</td>\n",
              "      <td>72</td>\n",
              "      <td>22.1</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>87</td>\n",
              "      <td>0.463</td>\n",
              "      <td>12</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>31</td>\n",
              "      <td>74</td>\n",
              "      <td>29.9</td>\n",
              "      <td>84.5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>125</td>\n",
              "      <td>0.268</td>\n",
              "      <td>19</td>\n",
              "      <td>35.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>376 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age Blood_Pressure   BMI Plasma_level  Autoimmune_Disease Adverse_events  \\\n",
              "0    30             64  35.1           61                   1              1   \n",
              "1    22             74    30           40                   0              1   \n",
              "2    21             70  30.8           50                   0              0   \n",
              "3    23             64  34.9         59.5                   0              0   \n",
              "4    25             76  53.2           81                   1              0   \n",
              "5    25             62  25.1           45                   0              1   \n",
              "6    35             84    35           68                   1              5   \n",
              "7    22             78  34.6         43.5                   0              1   \n",
              "8    23             68  29.7           37                   0              3   \n",
              "9    23             86  45.5           51                   1              2   \n",
              "10   21             66  28.1         44.5                   0              1   \n",
              "11   28             70  31.6         81.5                   1              3   \n",
              "12   54             78  35.2           75                   1              7   \n",
              "13   25             68  31.9           42                   0              3   \n",
              "14   43             58    34           49                   0              6   \n",
              "15   42             78  46.7         40.5                   0              7   \n",
              "16   21             52  24.6         49.5                   0              2   \n",
              "17   25             58  27.7         63.5                   0              2   \n",
              "18   23             74  33.6         53.5                   0              2   \n",
              "19   26             88  43.3         90.5                   1              0   \n",
              "20   24             56  33.3         38.5                   0              1   \n",
              "21   24             64  33.2         58.5                   0              4   \n",
              "22   31             78  33.8         86.5                   1              3   \n",
              "23   22             60  37.2         43.5                   0              1   \n",
              "24   60             68  30.1         90.5                   1              8   \n",
              "25   51             72  25.8           83                   1              5   \n",
              "26   37             58  29.5           72                   0              4   \n",
              "27   41             74  29.9           52                   1              6   \n",
              "28   28             78    39         60.5                   0              1   \n",
              "29   21             62  22.1         69.5                   0              0   \n",
              "..   ..            ...   ...          ...                 ...            ...   \n",
              "346  23             62    24         55.5                   0              1   \n",
              "347  24             88  44.5           87                   1              2   \n",
              "348  23             82  40.6         76.5                   0              1   \n",
              "349  40             88  38.2           84                   1              7   \n",
              "350  33             50  27.1         59.5                   1              6   \n",
              "351  55             72  37.7         51.5                   0              6   \n",
              "352  24             54  30.9           53                   0              3   \n",
              "353  25             68  30.5           64                   1              0   \n",
              "354  57             76  37.5           98                   1              8   \n",
              "355  36             70  36.4         93.5                   1              3   \n",
              "356  23             62  22.9         53.5                   1              3   \n",
              "357  37             70  30.8         52.5                   0              6   \n",
              "358  25             78  36.1           58                   0              1   \n",
              "359  25             52  28.5           41                   0              2   \n",
              "360  25             58  31.6           72                   1              2   \n",
              "361  45            102  32.8         66.5                   1              1   \n",
              "362  22             66  32.2         41.5                   0              2   \n",
              "363  21             62  40.7         69.5                   0              1   \n",
              "364  58             78  46.5         86.5                   0              0   \n",
              "365  24             85  37.4         47.5                   1              0   \n",
              "366  26             64  28.6         69.5                   0              5   \n",
              "367  26             66  23.6           50                   0              1   \n",
              "368  22             58  21.8         50.5                   0              2   \n",
              "369  24             80  34.8           56                   0              1   \n",
              "370  27             72  32.4           64                   1              3   \n",
              "371  24             74  26.3           58                   0              3   \n",
              "372  36             74  25.9         47.5                   0              1   \n",
              "373  23             70  39.1         60.5                   0              2   \n",
              "374  37             72  22.1           58                   0              4   \n",
              "375  31             74  29.9         84.5                   1              3   \n",
              "\n",
              "    Drug_in_serum Liver_function Activity_test Secondary_test  \n",
              "0             156          0.692            32           12.7  \n",
              "1              60          0.527            11              0  \n",
              "2              50          0.597            26           22.6  \n",
              "3              92          0.725            18            1.8  \n",
              "4             100          0.759            56            3.6  \n",
              "5              59          1.268            18           16.8  \n",
              "6              88          0.286            41           34.1  \n",
              "7              32          0.101            27           31.4  \n",
              "8              45          0.293            28            1.8  \n",
              "9             120          0.127            36           30.6  \n",
              "10             94          0.167            23           31.2  \n",
              "11            105          0.268            18           16.6  \n",
              "12            126          0.692            29           14.5  \n",
              "13            106          0.591            30            9.5  \n",
              "14            190           0.43            33           14.3  \n",
              "15             48          0.261            40           17.3  \n",
              "16             94          0.637            15           17.3  \n",
              "17            275            1.6            24           16.4  \n",
              "18            100          0.404            30            7.9  \n",
              "19            510          0.222            44           16.7  \n",
              "20             56          1.251            30           11.5  \n",
              "21            120           0.23            27           10.7  \n",
              "22            185           0.97            39            2.4  \n",
              "23             75          0.509            37           25.9  \n",
              "24            495          0.615            36           12.1  \n",
              "25            175          0.587            19           10.5  \n",
              "26            140          0.287            28           24.4  \n",
              "27            156          0.722            18           29.4  \n",
              "28             74          0.261            39             19  \n",
              "29            210          0.207            17              0  \n",
              "..            ...            ...           ...            ...  \n",
              "346           182          0.138            13           35.4  \n",
              "347           120          0.646            37             20  \n",
              "348           485          0.687            42           20.2  \n",
              "349           321          0.787            42           31.6  \n",
              "350           176          1.318            22           27.7  \n",
              "351           190          0.324            32           18.7  \n",
              "352           158          0.292            21           11.8  \n",
              "353           180          1.391            19           26.4  \n",
              "354           280          0.605            29            1.2  \n",
              "355           200          0.408            22            6.7  \n",
              "356            48          0.678            13           13.8  \n",
              "357            68          0.122            32            1.3  \n",
              "358           180          0.496            29           29.9  \n",
              "359           115          1.699            22            2.7  \n",
              "360           135          0.422            33            4.7  \n",
              "361           140          0.234            28           35.2  \n",
              "362            50          0.497            23             16  \n",
              "363           480          0.536            41           27.7  \n",
              "364           265          1.159            32             12  \n",
              "365            36          0.247            25           10.8  \n",
              "366           140          0.411            35           23.1  \n",
              "367            56          0.666            15             24  \n",
              "368            90          0.155            35           31.5  \n",
              "369           132          0.217            45           34.6  \n",
              "370           190          0.549            25           24.1  \n",
              "371           105          0.107            15             23  \n",
              "372            73          0.673            21           31.6  \n",
              "373            95          0.886            32           31.3  \n",
              "374            87          0.463            12            0.5  \n",
              "375           125          0.268            19           35.5  \n",
              "\n",
              "[376 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "9quyXUt1_VFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d20d1af-1ae7-4418-db6d-f96626802da4"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(376, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "OUI5fwFyZk84",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split Train and Test"
      ]
    },
    {
      "metadata": {
        "id": "Kbp19FsAZuP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For any machine learning algorithm, the first task is to divide the data into test train dataset. This is because if we train the model using the entire dataset, the model would perform 100% accurate on the test data, but might not perform well on the new examples. Hence, we should split the data into test, train datasets and train the model using training dataset."
      ]
    },
    {
      "metadata": {
        "id": "zgjgJdoGaXVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fded7ade-64cc-4f63-c709-d6ed254a9abc"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = autoimmune_data.drop(columns = ['Autoimmune_Disease'])\n",
        "y = autoimmune_data['Autoimmune_Disease']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(282, 9)\n",
            "(94, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dJ5rmMWK7Eql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### kNN (k Nearest Neighbours)"
      ]
    },
    {
      "metadata": {
        "id": "bnt0fTo9mnHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c410834-7c6b-416c-c5fc-d9c3d7a516ab"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "autoimmune = KNeighborsClassifier(n_neighbors=5)\n",
        "autoimmune.fit(X_train, y_train)\n",
        "accuracy = autoimmune.score(X_test, y_test)\n",
        "print(\"The accuracy of the model using k=5 is {}\".format(accuracy))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model using k=5 is 0.7340425531914894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dIpH2C_wYRht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ]
    },
    {
      "metadata": {
        "id": "JJUDlkwcZkKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7af06650-07b7-4373-bfb6-d52372454fa5"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(autoimmune, X, y, cv=10)\n",
        "print(scores)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.73684211 0.65789474 0.68421053 0.76315789 0.68421053 0.73684211\n",
            " 0.76315789 0.78947368 0.72222222 0.75      ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XnWjr-VwZ3GV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe31048-d3b0-43e7-9012-460c3014385e"
      },
      "cell_type": "code",
      "source": [
        "print(\"Mean of 10-fold cross validation scores : {}\".format(scores.mean()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of 10-fold cross validation scores : 0.7288011695906433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kmZVbZZdaW15",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Selection - Finding optimal values of k"
      ]
    },
    {
      "metadata": {
        "id": "ztsCKgiCamw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "70a1bc41-867a-42ef-dc09-adf5adf64ed9"
      },
      "cell_type": "code",
      "source": [
        "k_range = range(1,20)\n",
        "k_scores = []\n",
        "for i in k_range:\n",
        "  autoimmune = KNeighborsClassifier(n_neighbors=i)\n",
        "  k_scores.append(cross_val_score(autoimmune, X, y, cv=10).mean())\n",
        "\n",
        "print(k_scores)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6861111111111111, 0.6942982456140352, 0.6916666666666667, 0.7261695906432748, 0.7288011695906433, 0.7421052631578947, 0.7501461988304092, 0.7635964912280702, 0.7529239766081871, 0.7421052631578948, 0.7554093567251462, 0.7605263157894736, 0.7605263157894736, 0.7364035087719298, 0.7549707602339181, 0.7467836257309942, 0.7549707602339182, 0.7521929824561403, 0.7548245614035088]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tq9p5cxKcSFa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plotting the scores:"
      ]
    },
    {
      "metadata": {
        "id": "CFRzR6frcTsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "2bfb80ff-e133-42cb-e6f6-21778086efb5"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('score')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'score')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl41fWZ8P939pCVJIQQAiGE5RZI\nQFEURGSzuKG4dlNbpjrdtLVPr/7mcmb6dKZ15plnpk/rjK2dThertWrVIlTFBRFFEJBF2eGWPQmB\nJISQlezn98c5icdDQg7kfM+S3K/r8jLf7Zw7h5xzn8/yvT9RLpcLY4wxBiA61AEYY4wJH5YUjDHG\ndLOkYIwxppslBWOMMd0sKRhjjOkWG+oA+quqqj6sp09lZCRRU9MU6jD8EimxWpyBFSlxQuTEGglx\nZmenRvW031oKDouNjQl1CH6LlFgtzsCKlDghcmKNlDh7YknBGGNMN0sKxhhjullSMMYY082SgjHG\nmG6WFIwxxnSzpGCMMaabJQVjjDHdLCmYAaXqzFlefPcgTc3toQ7FmIgU8Xc0G+Ptubc/Ycehappb\n2vnKDZeEOhxjIo61FMyAcexkPTsOVQPw3vZyDh6vDXFExkQeSwpmwHjlgyMALLlmLAB/fHM/7R2d\noQzJmIhjScEMCCUV9Xx84BTjRqZx6+wCrp02krKqRt7eWhrq0IyJKJYUzIDw2oajANwyeyxRUVHc\nNW8cqUlx/HX9EU7Vng1tcMZEEEsKJuKVVTWwVasYm5tKcWEmAClD4vjiggm0tnXy7KpPcLnCusK6\nMWHD0dlHIvIYMBNwAQ+r6hbP/jzgWa9TC4FHVPU5EfkBcC/QBny76xpjeuPbSugyc0oO63edYMeh\naj76pIrLZXiIIjQmcjiWFERkLjBBVWeJyCTgSWAWgKoeB+Z5zosF3gNeEZEpwBeBK4CpwBLAkoLp\nVfmpRrbsqyQ/J4Vp47I+cywqKop7F03kn57czHOrDzC5IJMhCYNnFnZrWwd/WXuIA6Xnn4UVGxdN\ne9v5B+SvuCSbm2cVBDA6E66cfIcsBFYAqOo+EckQkTRVrfM5bymwTFUbRGQx8KKqtgMfef4zplev\nbTyKC7jVp5XQJTcrmZtmjuGVD46yfN1hvnzdxKDHGAqVNU38avluSiobiIuNJjq6x0W2AIiOgs7z\n9K61tnVw8nQT11+ZT2yM9TgPdE4mhRHANq/tKs8+36TwALDI83MB0CEibwJxwPdVdcf5niQjIyns\nVznKzk4NdQh+i5RYs7NTOV7VwOa9FRTkpvG5WWN7/eD76i1FbNUq1mwr4+Y54xg/amhQ4wy2D3ef\n4LHnP6KxuZ0bZhXwt0uKiI+7+PfIb1bs4tV1hznV0Ebx+GEBjPTiRNLfaCQKZlv6nHesiMwC9nu1\nHqKAGOBGYDbwO2DG+R40AtZBpaqqPtRh+CVSYu2K85nX9tLpgpuuyqe6uuG819xz3QR++uft/Nfz\nH/HDr1xx3m/OgY4zWDo6O1n+/hFe33SMuNho7r95ErOLc6k9c/73SF9xFuakAPDB9jJGpCcENOYL\nFWl/o+Gst6TlZFuwHHfLoMtI4ITPOYuB1V7bFcD7qupS1fW4Ww7GnKOypomNeyrIG5bMdMnu8/xJ\nBZnMmpLD0ZP1rPmoLAgRBldtYys/+/N2Xt90jOEZQ/jhV65gdnFuQB77kvwMYqKj2H34dEAez4Q3\nJ5PCKuAuABGZDpSrqm/qnAF4dw+9AVzvueYSwO48Mj16beMxOl0ubpldQHQPYwk9+cKCCSQnxvLy\n+4epqW9xOMLgOVB2hn/+w2b2l5zhsgnD+NFXZzB6eErAHj8hPoYJo9I5VlFPXVNrwB7XhCfHkoKq\nbgC2icgG4HHgQRFZKiK3e52WC1R6XbMJOCYiG4E/AA86FZ+JXCerG9m4+yS5WUlccQHTTNOS47lr\n3jiaWzt4fvUnDkYYHC6Xi1WbS/iP5z6mvrGNu+eP46E7iklKDHyv8JSx7vs/9h611sJA5+iYgqo+\n4rNrh8/x4h6u+Sfgn5yMy0S2v6w5QEeni8VXF1zw2MCcaSP5YPdJtmoVOw+dYuq40A+cXoyzLe38\n4fV9bNUq0pLj+daSKUh+hmPPVzQ2i2VrD7Pn8GlmTh7R9wUmYtn8MhNRqmubeWdLCTkZQ7hy0oXf\njBYdFcVXrhdioqP406pPaGnrcCBKZx2vauDRp7eyVauYOCqdf/6bGY4mBIDROSmkJsWx++hpuzt8\ngLOkYCLK6x8eo73D3UqIib64P99R2SksunI0p2qbuyurRoqNe07y6B+3cvJ0Ezdcmc8PvnQZQ1Oc\nnxEUHRXFlIJMahtaOX6q0fHnM6FjScFEjJr6FtbtKGdEVhIzp+T067FunT2WYemJrNpcSlnl+aez\nhoO29k7+tEr57at7iY6K4sHbi/j8gvFBvZmsa1zBZiENbJYUTMR4Y5O7lfD5hRMvupXQJSEuhnsX\nTaSj08XTb+2nM4y7RKprm/m/z37Emo+Ok5edzI+WzghJHaeupLDHBpsHNEsKJiKcaWhh7Y5ystIS\nmX/F6IA85tRxw7hCsjl0vI73d5QH5DEDbfeRan781BaOnKhj1pQcfnjfFYzITApJLENTEhiVncIn\npWdojcCxGOMfSwomIrz5YQlt7Z3cfPWYgHaZfOm6iSTGx/CXdw9R2xhec/Df/aiMx17YQXNrO/dd\nLzyweDIJ8aEt6VI0NpO29k4+KTsT0jiMcywpmLBX29jKex8fJzMtgdlFgblLt0tGagJ3XFtIU0s7\nL6w5ENDH7o/6plZefPcQKUlx/P29lzP/srweC/4FW3cX0pHgdiF1uly8+sER9hyuDurz+mo428aL\naw6yTSvp6AzdUq+tbR2UOzTgP3jqCJuI9dbmElrbO7lp5hjiYgP/PWbB9FFs2H2STXsqmF2cy5SC\nzIA/x4V6a3MpLW0d3DG3kLG5aaEOp9vE0enExUYHPSloyRmWrzvCm5tL+eFXLic3Kzmozw/u2lK/\n/utu9h6tAdxfKOZdOpJrL80jPTk+KDGUVTXw/vZyNuw+SVNLOz/52pWMCuDd62AtBRPm6ppaWfNR\nGUNT4pkzNbCthC7R0VF89YZLiIqCP72ltLWHtr+8vqmVd7aVkZ4Sz9xpI0Mai6+42Bhk9FDKqhqD\nWipk056TgPumvceX7aKpuS1oz93lpXcPsfdoDcWFWSyYnkdTSzvL1x3hB098wG9e2cPB47WO3MPR\n0tbB+p0n+NdntvKj329m9bYyYmOjuXV2AbnDAj++ZC0FE9be3lJKa1snd80dQ5yDJdLHjEhl4eWj\nWL21jJUbj3HbnELHnqsv3a2Eawv7VfLaKVPGZrL7yGn2Hj0dsKJ759PW3sFWrSQjNYG500exYu0h\nfvPqXr5759SgVLsF2LD7BKu2lJKblcQ3l0xhSEIsd84dx4bdJ1nzURmb9lawaW8F+TkpLJg+ipuv\nHdfv5yypqGftjnI27angbEs7UUBRYSZzp+UxbXyWY9ORLSmYsNVwto3V28pIT47n2iB8Y759TiHb\ntIrXNx3jqsk5IemiqG9q5Z2P3L/z3EvDq5XQpWhsJi/gHlcIRlLYcbCasy0dzL00j6WLp3CwtIad\nh6p5+f3D3DWv/x++fTlyoo6n3lCGJMTynTundq/eNyQhloWXj2LB9Dz2l5xhzUdlfPzJKZ56Yz9/\nee8Qs4tHMP+yPIZn+P9tvrm1nc37Klm7vZwjJ9wrCgxNiee6ywuYMzWXYUOHOPI7erOkYMLWqi2l\ntLR2cPs1Y4PyjXlIQixfvm4CTyzfzTNvKf/fly4L+uBu1+98x5zwbCUAjByWzNCUeHYfOU2ny+V3\nldqLtWlvBQCzpowgJjqKb9w6hUef3srrm46Rn5PClZP6dyPj+dQ2tPDLl3fR0dnJd5YU9zgdOCoq\nikljMpg0JoPTdc28t72c9TtP8NbmUlZtLqXI091UPC6r19fq6Mk63t9ezsa9FbS0dhAVBdPGZTH3\n0jyKx2X2+76cC2FJwYSlxuY23tlWSlpSHHMvywva806fmM20cVnsOFTNxj0nuTrAs53Ox7tlFK6t\nBHB/CE4Zm8kHu05SWtHAmBHOrTDW2NzGzkOnyMtO7i4HnpwYx3funMq//HErT67cx4jMJPJzAh9D\ne0cnT6zYTU19C3fPG0dxYVaf12SmJXLHtYV8bUkRb64/zJqPjrPrcDW7DleTPTSR+ZeN4pqpuaQM\nieNsSzsf7q1g7fZyjlXUe65P4MYr87lmai6ZaYkB/538YUnBhKXVW8s429LB4vkFJATxG3NUVBT3\nfG4i+459yItrDjJt/DCSE+OC8txvbS5xt4zCuJXQpWhsFh/sOsnuI9WOJoWt+ytp73Axc/JnWwN5\nw5L5+i2T+cWyXfxi2S7+99IrSEsK3Awgl8vFn1Z9wsGyWq6anMMNV+Vf0PVxsTHMnDKCmVNGUFLh\nXthp054KXnz3IMvXHUbyh3puAuwkOiqKyyYMY+6lIykamxW0cZLe2OwjE3aamtt5e0spKUPimB/E\nVkKXYUOHcMvsAuqa2nh57eGgPGfD2Tbe2VZGWnI888K4ldBlckEGUTh/v8LGPe6uo57KdV82IZvb\n5oyluq6Z/16+m/aOwN038N7Hx3l/Rzn5OSksvfGSfnUj5ueksvTGSfzsodl8YcF4MlIS2H34NGlJ\n8dx+bSE//fbVfOfOqUwdNyzkCQGspWDC0DsfldHU0s6dcwtJjA/Nn+j1V+azYfdJ3vv4OLOLcykc\n6ey9Aqu2lNDc2sFtQRo/6a/UpHjyR6RyoKyW5tZ2R/6dqmub+aT0DBNHDyUrveeulMVXF1Ba0cC2\nT6p44Z2D3LNoYr+fV0tqeG71AVKT4vjOHVMD1lJNTozj+ivz+dwMd4XeYemJjo/HXAxrKZiwcral\nnVWbS0hOjGXB9FEhiyM2Jpr7Fgku4Jm3lM5O5wrmNZxtY/VWdyshmOMn/VU0NpOOThda4kzJiw/3\ndQ0w9z6QHB0Vxf2LJ5GXncw7H5Wxrp81rKprm/nVit0AfPu2ol6TUX9ER0UxfOiQsEwI4HBLQUQe\nA2YCLuBhVd3i2Z8HPOt1aiHwCBAPPAoc8ux/W1X/1ckYTXhZ81EZjc3t3D5nbPfUv1C5ZEwGs6aM\nYOMe91z06wJUiM/Xqi2lNLd2sOSasUEdP+mvorGZrNx4jN1HTjNtfOBXsNu45ySxMVFcccn5K8Im\nxrunij761BaeWaXkDktmfF76BT9fS1sHv3x5F/VNbdy7aKLjCxeFK8daCiIyF5igqrOA+3Gv0wyA\nqh5X1XmqOg+4DigBXvEcfqHrmCWEwaW5tZ23Npd65n878wF8ob6wYDxJCbEsX3eYMw2Bv4PX3Upw\nz7KaF0GtBIBxeekkxMc4Mq5QWtnA8apGiguz/BroHz50CN+8rYiOThdPvLzrgu+2drlcPPXGfo5V\n1HPttNyQjGWFCye7jxYCKwBUdR+QISI9dcwuBZapavivdGIc43K5eHHNQRrOtvG5K0Y5svj8xUhL\njufOeeM429LBC2sOBvzx3/a0Em64akxEtRLA3cU2KT+Dk6ebOFV7NqCP3VXWYtYU/9eDnlKQyRfm\nj6e2sZVfvrzrgsqVvLm5hA/3VjA+L517PidhUXwwVJx8540AtnltV3n21fmc9wCwyGt7roi8CcQB\nP1DVj8/3JBkZScQ6WP4gELKznZuyF2ihinXl+sO8t72csSPTuO/mKST20XUUzDjvvE74cF8FH+6t\nYPGcQi6d6P8CN+eLs6Hr7uWUeO7+nPT5OzvpYl/Pq4pz2X7wFCWnmpg0PjAL/3R2utiyv5LkxFgW\nziw4Z+D9fLF++abJVNa1sGZrKS+8d5jvfbHvGxC37a9g2XuHyEpP5EcPzCQjQPcHRNL73lsw/wrP\n+ZcRkVnAflXtShSbgCpVXek59keg+HwPWlPTFPBAAyk7O5WqqvpQh+GXUMW69+hpfrNiN2lJcXx7\nSRH1dWc5XxShiPNLCybwk6e38MuXdvCTr13pV7XWvuJcse4wTc3tfH7++D5/Zyf15/Uck+0uBbJp\nZznTx/V9c5c/9h+r4VRtM3Om5lJ75rPvb39i/cK8Qo4cP8OaraXkpCfyuRm9d0VWnG7i3/+4lejo\naL59WxHtLW1UVfW/2F4kvO97S1pOdh+V424ZdBkJnPA5ZzGwumtDVfer6krPzxuBbBEJ72aA6ZeK\nmib+e8VuoqLgwTuKHZntEQhjRqSyYPooKk438caHx/r9eI3Nbby9tZTUpNDcixEoORlDGJaeyN6j\nNQGbobXR03U08wK6jrzFxcbw4O3FpCXH88Kag+ztZflQd8XVnZxtaeerN0hYlSgPJSeTwirgLgAR\nmQ6Uq6pv6pwB7OjaEJG/E5EveX4uwt1qsHX/Bqim5nYe/8tOGpvb+coNwoRRQ0Md0nndPqeQ9OR4\nXttwjMp+tlDf3lLK2ZYObrgqP+SrqfVHV8mLppb27gJu/eGuiFpFRmoCkn/xfw+ZaYk8dHsxUVHw\n3yt2U3Xms2MenS4Xv311Lyeqm1g0Y3RQCvtFCseSgqpuALaJyAbcM48eFJGlInK712m5QKXX9nPA\n10VkLfA/uGctmQGos9PFb17d0/2mnDM1/O/iTUqM5YsLJ9De0cmzbx+46Nr5Tc1tvL21jJQhcSy4\nLHT3YgRK16JEgZiFtPNQNWdb2rlqck6/5/GPH5XOfdcLjc3t/GLZLppb27uPvbL+CNsPnmJyQQZ3\nz3e+0mokcXRMQVUf8dm1w+d4sc92GTDfyZhMePjL2kPsPFRN0djMiHpTXjlpOOt2lrPrcDXbtKrP\nOfQ9eXtrGWdb2rl73riIbiV0mVyQQVQU7D56mluvGduvx/q0rEVgKp9eO20kxyrqefej4zy5ch/f\nuq2Ijz6p4pUPjjIsPZFvLikKagXSSGCvhgm6D3ad4M0PS8jJdC9YEklvyqioKO5dJMTGRPH8Owc4\n29Le90VemprbWNVV12l65I4leEtKjKNwZBqHj9fR1Hxhr4e3niqiBsKXFk5g4uihbNUqnn5T+d1r\n+0iIi+G7d04lZUhwih1Gksh5N5oB4dDxWp5+cz9DEmL57p3FJAWpAmkgjchM4qaZY6ipb+Gv649c\n0LVdrYQbrsoPWV0nJxSNzaLT5WLfsZqLfgzviqiBvE8gNsY9sygrLYH3d5TT0tbBA4snBXxt44HC\nkoIJmtN1zfzi5V10dLr41m1TQrKyWaDcNHMM2UMTWb21jNJK/+67bGpu667+umCAtBK6TBnrGVfo\nZaaPPzZ5uo6uClDXkbe05HgeumMqWWkJ3DVvHJdLYO6pGIgsKZigaGnr4BfLdlHX2MoXFkygaGxg\n5rSHSnxcDPcuEjpdLnfBPD8GnVdvdVd/vf7K0QOqlQAwNjeVIQmx7D5cfVED8NW1zainIuqwdGeW\nnBwzIpX/+NbV3DRzjCOPP1BYUjCOc7lc/OH1fRyrqOeaqbl87orIn3EDUFyYxRWSzcHjtazf6XsL\nzmc1Nbd3jyWEsvqrU2Kio5lckMGp2mYqz1x4yYuuiqgzz1MRNRAGc/kKf1lSMI57bcNRNu+rdE8R\nXDSw6sp86bqJJMTH8NK7B6lvau31vNXbSrtbCaGu/uqU7i6ki5iauslTEXXGRczmMoFlScE4aptW\nsXzdEbLSEnjo9mK/ykNEkozUBG6/ZiyNze289N6hHs/pWkku1GtEOK3Ic7/C7sMXlhRKKxsou4CK\nqMZZA+sdasJKaWUDv3ttL/Fx0XznzqmkJQduDd1wsvCKUYwensL6nSc4UHbugjPvbCulsbmd66/M\nH7CtBHAvY5qTmcS+kpoLWhrzYiqiGudYUjCOqGts5fG/7KSlrYO/XTyZ/JzIrBjpj5joaO67XgD4\n41v6mQ/Esy3usYTkxFgWXj5wWwldigoyaWnt4HC5fyUvOl0uNu2tYEhCDNPGR/bkg4HCkoIJuPaO\nTn61fBfVdc3cds3YQTH9b3xeOtdOy+V4VSOrt5Z171+9rWxQtBK6dI0r7D5S7df5n5Scoaa+hctl\nOHFhXgJ/sLCkYALK5XLxp1XKJ2W1XHHJcG6ZXRDqkILmrnnjSRkSx1/XH+F0XbP77mXPetODoZUA\ncMmYocRER/k92Lxpr3UdhRtLCiagVm8r4/0dJ8jPSeH+mycNqJlGfUkZEsfd88fR0tbB86sP8Nr6\nIzQ2t7NokLQSwL1e8vi8dI6eqKfh7PnXJWhr72DL/v5XRDWBZUnBBMzuI9X8+Z0DpCXH8907p0bc\n8pKBMLs4lwmj0tn2SRUvvK0kJ8Zy3SBpJXSZMjYTF/S6jkGX7oqok/pfEdUEjiUFExDVtc38esUe\nYqKjeOiOYjIDtKRhpImOiuK+64WY6Cha2ztZNGPg3pfQm6LCrnGF8yeFrrIWTt+wZi6MJQUTEK9u\nOEJTSztfvm4i4/PSQx1OSI3KTuH2awsZP3ooCy/vfSnIgSo/J5WUIXHsOXK615IXjc1t7Dh0irxh\nga2IavrPkoLpt1NnzvLBrpOMyEzi2mnhv1hOMNw0cwyPfW8uSYmDq5UA7tbS5IIMaupbKK/ueYW6\nbVrlrog6JbAVUU3/OfoXKyKPATMBF/Cwqm7x7M8DnvU6tRB4RFWf8xzPAfYDt6vqe07GaPrvtY3H\n6Oh0ccvsAqKj7Q1u3KW0N++rZM+R0+QNO7cabtcNa05URDX941hLQUTmAhNUdRbuZTUf7zqmqsdV\ndZ6qzgOuA0qAV7wu/ylw2KnYTOC4WwknyMlM4qpJ9gY3buerg3S6rpn9JWeYOCrdsYqo5uI52X20\nEFgBoKr7gAwRSevhvKXAMlVtABCRBUA9sMvB2EyArNzkbiXcerW1EsynMlITyBuWjJbU0Nbe8Zlj\nH+71DDAX2b0J4cjJ7qMRwDav7SrPPt/73x8AFgGISDzwT8AS4D/9eZKMjCRiw/xOyOzsyCnxcCGx\nVp5uYv3OE+RlJ3PzteOIiQneEFWkvKaDOc4ZU0awYu0hqurbmDbx0/sQtmgVsTFR3DC7kNSkC6+H\nNZhf02AI5ijYOV8jRWQWsF9VuxLFI8BvVfWMiPj1oDU1PQ9khYvs7FSqqupDHYZfLjTWZ97cT0en\nixuvyuf06UYHI/usSHlNB3uchTnuWUUfbC9jZIZ7inJZZQNHT9Rx2YRhNDe20NzYEhaxBlokxNlb\n0nLyq1057pZBl5GA70oki4HVXtvXAw+JyCbgZuBXIjLFwRjNRTpVe5Z1O0+QkzHEBgtNjyaMHkps\nTPRn7lfYaGUtwp6TSWEVcBeAiEwHylXVN3XOAHZ0bajqbFWdqaozgZXAt1V1j4Mxmov0umfG0eKr\nC4iJtpnN5lwJcTHI6HRKKxuobWih0+XiQ6uIGvYcezer6gZgm4hswD3z6EERWSoit3udlgtUOhWD\ncUZ1bTPrdp5geMYQuxvVnNcUz1rce4/WcKD0DKfrrCJquHN0TEFVH/HZtcPnePF5rl3qREym/7pm\nHN1irQTThyljM+Fdd12srkQwy7obw9rgu93S9MvpumbW7Si3VoLxy6jsZNKT49l95DQdHS5PRdSM\nUIdlzsO+5pkLsnKjtRKM/6KiopgyNpP6pjaauiqi2v0sYc3e1cZvp+uaWbeznOFDrZVg/FfkubsZ\nrCJqJLDuI+O3lZuO0d5hM47MhZlckElUFIzMsoqokcCSgvFL11hC9tBEZhXZtz3jv7TkeL539zQy\nUxOsImoEsKRg/PK6tRJMPxQX2n0JkcLe3aZPNfUtvN/VSrA7UY0Z0CwpmD69vtHTSphVQGwQi94Z\nY4LP3uHmvGrqW1i7o5xh6YnMslLHxgx4lhTMebnHEjpZfLW1EowZDOxdbnpVU9/C2u3uVsLV1kow\nZlCwpGB69Ya1EowZdOydbnp0puHTsQRrJRgzeFhSMD16fdMx2tqtlWDMYGPvdnOOMw3usYSsNGsl\nGDPYWFIw53hjU4mnlTDGWgnGDDL2jjefcaahhfe2HycrLYHZxbmhDscYE2SO1j4SkceAmYALeFhV\nt3j25wHPep1aCDwCrAaeBhKBeOD7qvqhkzGaz3rzQ3cr4WYbSzBmUHLsXS8ic4EJqjoLuB/3Os0A\nqOpxVZ2nqvOA64AS4BXgXuAZVZ0P/APwqFPxmXPV1DXz7sfuVsI11kowZlBysqWwEFgBoKr7RCRD\nRNJUtc7nvKXAMlVtAH7utX80UOZgfMbHy+8ddLcSrMaRMYOWk0lhBLDNa7vKs883KTwALOraEJER\nwKtAKrCgryfJyEgi1rMgeLjKzk4NdQh9qqlv5vUNRxk2dAi3LZhIXGx4J4VIeE3B4nRCpMQaKXH6\nCuZ6CuesriEis4D93q0HVT0JzBCRm4Cn8EoYPampaQpwmIGVnZ1KVVV9qMPo0wtrDtDa1sGNV+Vz\npqYx1OGcV6S8phZn4EVKrJEQZ29Jy6+vgyJys4g85Pl5nIj4s3xSOe6WQZeRwAmfcxbjHlzuep65\nIpIBoKqvA9P9ic9cvNrGVl7fdIx3PzrOsKFDbCzBmEGuz5aCiPw7MAEYA/wS+DIwHPhOH5euAn4M\n/I+ITAfKVdU3dc4A/uy1fQdwGfCfIlIMlPrzS5gL0+lysffIadbuKGf7gVN0dLqIi43mgSVFYd9t\nZIxxlj/dR3NVdaaIvAugqo+KyAd9XaSqG0Rkm4hsADqBB0VkKVCrqss9p+UClV6XPQo8LSJ3AAnA\nty7gdzF9qKlvYf2uE6zbUc6p2mYARmWnMPfSkcyaksOY0Zlh3+Q1xjjLn6Rw1vN/F4CIxPh5Har6\niM+uHT7Hi322TwE3+/PYxj+dnS52H6lm7fZydhysptPlIj4umjlTc5l7aR5jc1NtMXVjTDd/Ptw3\niMgfgJEi8n3cXTzvORqV6bfTdc2s23mCdTvLOV3XAsCYnFTmXjqSqybnMCQhmHMMjDGRos9PBlX9\nRxG5C2gCRgE/V9WXHY/MXLCOzk52HnK3CnYdrsblgoT4GOZdOpJrLx1JwYi0UIdojAlz/gw0P6Kq\n/xf4SxDiMRehuraZtTvKWb+znDMNrQCMzU1j7qUjuXLScBLjrVVgjPGPP58WRSIyXlUPOh6NuWCN\nzW38+KktNJxtY0hCDAum53HrA3hrAAAWF0lEQVTttJHk50TmjTPGmNDyJylMBfaJSDXQivsmNJeq\n5jsamfHLkRN1NJxtY3bRCO69XkiIC++7u40x4c2fpHCL41GYi1ZS0QDApROGWUIwxvSbP0mhDPcN\nazNwT0vdpKrPOxqV8duxk+77Cqy7yBgTCP7cvvo4cCugwAHg8yLyX45GZfxWUlFPUkIsw9ITQx2K\nMWYA8GugWVXnem3/UkTWORWQ8d/ZlnYqas5ySf5QuwHNGBMQ/rQU4kWk+7wLuaPZOKu00j2eYF1H\nxphA8efDfSWwRUTWerbn89kidiZESirc4wljLCkYYwKkz5aCqv4L8CBwDDgKfENV/93huIwfumYe\n5eekhDgSY8xA0WdSEJFc4EpV/S9VfRy4VUTynA/N9OVYRT1xsdGMyEoKdSjGmAHCnzGFPwAnvbZ3\nAU86E47xV1t7J+WnGhk9PIWYaFsDwRgTGP58miSq6otdG6r6AhDnXEjGH+WnGunodNkgszEmoPwZ\naHaJyA3AWtxJ5EZnQzL+OFbRddOajScYYwLHn6Twt8CvgZdwr6C22bOvTyLyGDAT953QD6vqFs/+\nPOBZr1MLgUeAF4HfA+M8sf1AVdf79ZsMMjbzyBjjBH+6j64BlgMZuMcTBFjU10UiMheYoKqzgPtx\n3xkNgKoeV9V5qjoPuA4oAV4B7gMaVfUazzU/v6DfZhApqWggOiqKUdnJoQ7FGDOA+JMUvgH8FrgN\nd1IoAL7gx3ULgRUAqroPyBCRnlZ5WQosU9UG4E/A9z37q4AsP55n0OnsdFFSWc/IYUnExVoRPGNM\n4Pi1RrOqtorITcCfVLVTRFx+XDcC2Oa1XeXZV+dz3gN4Wh6q2ga0efZ/D3iuryfJyEgiNsw/GLOz\nA9vFU1pRT2tbJxPHZAb8sQP9eE6xOAMrUuKEyIk1UuL05Ve5ChF5ApgN/K2IzAIupvraOcV5PI+1\nX1XrfPY/CEzHj7LdNTVNFxFK8GRnp1JVVR/Qx9y+3z1DeHh6YkAf24lYnWBxBlakxAmRE2skxNlb\n0vKn++ge3NVRb1XVDtzdR9/047py3C2DLiOBEz7nLAZWe+8QkftxJ4PbPC0H46PrTuYxNvPIGBNg\nfbYUVPUE8J9e2/6upbAK+DHwPyIyHShXVd/UOQOvOkoiUog74cxV1WY/n2fQ6Zp5NHp4ZDZPjTHh\ny7Fqp6q6QUS2icgG3FNZHxSRpUCtqi73nJYLVHpd9gDuweXXRaRr3yJVbXUqzkjjcrkoqWgge2gi\nSYlWrNYYE1iOfqqo6iM+u3b4HC/22f4H4B+cjCnSna5roeFsG5fkDw11KMaYAciK5kSYkgpbftMY\n4xxLChHmmCUFY4yDLClEGJt5ZIxxkiWFCFNSWU96cjzpKQmhDsUYMwBZUogg9U2tnK5rYcwI6zoy\nxjjDkkIEseU3jTFOs6QQQbpnHtlNa8YYh1hSiCDdM4+s+8gY4xBLChGkpKKBIQmxZKdfTD1CY4zp\nmyWFCNHc2k7F6Sbyh6cQFXVOwVljjAkISwoRorSyARfYzCNjjKMsKUQIm3lkjAkGSwoRwspbGGOC\nwZJChCipqCcuNprcrKRQh2KMGcAsKUSA9o5Ojlc1Mio7mZho+yczxjjHPmEiQPmpRjo6XYyxriNj\njMMsKUSAYydtPMEYExyOrrwmIo8BMwEX8LCqbvHszwOe9Tq1EHhEVZ8TkbnAS8DXVPU1J+OLFJ/O\nPLKkYIxxlmNJwfPhPkFVZ4nIJOBJYBaAqh4H5nnOiwXeA14RkXHA94EPnIorEh2rrCc6KopR2cmh\nDsUYM8A52X20EFgBoKr7gAwRSevhvKXAMlVtAE4AdwC1DsYVUTpdLkorG8jNSiI+LibU4RhjBjgn\nu49GANu8tqs8++p8znsAWASgqk0AIuL3k2RkJBEbG94fltnZF9/tc7yqgZbWDiaOyejX4/grGM8R\nCBZnYEVKnBA5sUZKnL4cHVPwcU7BHhGZBexXVd9E4beamqZ+BeW07OxUqqrqL/r67fsqAMhJT+zX\n4/ijv7EGi8UZWJESJ0ROrJEQZ29Jy8nuo3LcLYMuI3F3D3lbDKx2MIaIZzOPjDHB5GRSWAXcBSAi\n04FyVfVNnTOAHQ7GEPG6F9axmkfGmCBwLCmo6gZgm4hsAB4HHhSRpSJyu9dpuUBl14aI3Cwi7wE3\nAP8mIqucii8SuFwujlU0MCw9kaTEuFCHY4wZBBwdU1DVR3x27fA5XuyzvRJY6WRMkaSmvoWGs23I\n6KGhDsUYM0jYHc1hrPumNVtDwRgTJJYUwljXeMIYG08wxgSJJYUwZmsoGGOCzZJCGCupqCctOZ6h\nKQmhDsUYM0hYUghTDWfbqK5rsamoxpigsqQQpj4dT7CuI2NM8FhSCFNdM48sKRhjgsmSQpiyO5mN\nMaFgSSFMHauoZ0hCDMOGDgl1KMaYQcSSQhhqae3gZHUTo4enEh11TnFZY4xxjCWFMFRa1YAL6zoy\nxgSfJYUwZDOPjDGhYkkhDFlSMMaEiiWFMHTsZAOxMdGMyEoKdSjGmEHGkkKYae/o5PipBkZlJxMb\nY/88xpjgsk+dMFN+qpH2DpcVwTPGhISji+yIyGPATMAFPKyqWzz784BnvU4tBB4BXgKeAsYAHcDf\nqOphJ2MMN913MtsaCsaYEHCspSAic4EJqjoLuB/3kpwAqOpxVZ2nqvOA64AS4BXgy8AZVb0G+Ffg\n35yKL1zZnczGmFBysvtoIbACQFX3ARkiktbDeUuBZara4LlmuWf/amC2g/GFpZKKeqKiYFS2JQVj\nTPA52X00AtjmtV3l2Vfnc94DwCKva6oAVLVTRFwiEq+qrb09SUZGErGxMYGL2gHZ2f51BXV2uiit\namDU8FRGjQzNusz+xhpqFmdgRUqcEDmxRkqcvhwdU/BxTr0GEZkF7FdV30TR6zW+amqa+huXo7Kz\nU6mqqvfr3IrTTZxt6SBvWJLf1wTShcQaShZnYEVKnBA5sUZCnL0lLSe7j8pxf/PvMhI44XPOYtzd\nROdcIyJxQNT5WgkDTffym8Mj8xuGMSbyOZkUVgF3AYjIdKBcVX1T5wxgh881d3t+vgV418H4wo7N\nPDLGhJpj3UequkFEtonIBqATeFBElgK1qto1mJwLVHpd9gLwORFZD7TgHoQeNGzmkTEm1BwdU1DV\nR3x27fA5Xuyz3QH8jZMxhSuXy8WxinqGpSeSnBgX6nCMMYOU3dEcJs40tFLf1GZ3MhtjQsqSQpg4\nZl1HxpgwYEkhTFi5bGNMOLCkECa6Zh5Z95ExJpQsKYSJkop60pLiGJoSH+pQjDGDmCWFMNDY3Map\n2mbyc1KJiurzJm5jjHGMJYUwUHKya5DZuo6MMaFlSSEMHOseT7CZR8aY0ApmQbwBpaOzk6fe2E9T\ncztzpo2kuDCTmOiLy7EllZ6ZR1bewhgTYpYULtJL7x7ig10nAfj4wCkyUhOYMzWXOVNHkpWeeEGP\nVVLRQGJ8DNlDhzgRqjHG+M2SwkX4YNcJVm0pJTcria/ecAkf7q1g456TvPLBUV794ChFhVnMvXQk\nU8dl9flYLW0dnKhuZEJeOtE2yGyMCTFLChfocHkdT7+pJCXE8t07p5KTmcTE0UP5/PzxbN5Xwfs7\nytl1uJpdh6tJT4ln0VVjuGLCsF5bAWVVDbhcNshsjAkPlhQuQG1DC08s30VHZyffWFJMTmZS97GE\n+BjmTBvJnGkjKa1s4P3t5WzYc5KX3jnAS+8cYEpBBnMvzePSCcOIjfl07MFmHhljwoklBT+1tXfy\nxPLd1NS3cPe8cRQX9t41NHp4Cvcsmshd88fxSXkdr607zJ6jNew5WkNaUhyzi3O5dtpIcjKTumce\n2SCzMSYcWFLwg8vl4tm3lYPHa7lqcg43XJXv13UJcTEsuCKf4jEZHD/V6G497D7BGx+W8MaHJVyS\nP5SqM83ExkSTm5XU9wMaY4zDLCn44d2Pj/P+jhPk56Sw9MZLLuqu47xhyXzpugncNa+QbVrF2u3l\n7C85A7hbCd5dSsYYEyqWFPqgJTU8v/oAqUlxfOeOqSTExfTr8eJiY5g5ZQQzp4zgRHUjm/dVckn+\n0ABFa4wx/eNoUhCRx4CZgAt4WFW3eB0bDTwPxAMfqeo3RSQa+DVQBLQC31TV/U7GeD6nas/yqxW7\nAfj2bUUXfP9BX3KzkllyzdiAPqYxxvSHY30WIjIXmKCqs4D7gcd9TvkZ8DNVvRLoEJF8YAmQrqpX\ne675f07F15eWtg5++fIu6pva+PJ1E5D8jFCFYowxQeNkR/ZCYAWAqu4DMkQkDcDTIpgDvOI5/qCq\nlgATgM2efYeAMSLSv/6ai+ByufjD6/soqWjg2mkjmXdZXrBDMMaYkHCy+2gEsM1ru8qzrw7IBuqB\nx0RkOrBOVf8e2AX8LxH5T2A8UAgMAyp6e5KMjCRiYwObN5atOcDmfZVMKsjke1++nLjY/uXO7OzI\nmW4aKbFanIEVKXFC5MQaKXH6CuZAc5TPz3nAfwFHgZUicrOqrhSR2cD7wE5gn89156ipaQpokLsO\nV/P0yr1kpCbw9cWTOFPT2K/Hy85OpaqqPkDROStSYrU4AytS4oTIiTUS4uwtaTmZFMpxtwy6jARO\neH4+BRzzdBEhIu8AU4CVqvrDrgtE5BBQ6WCMn3HydBO//useYmKieeiOYtJTEoL11MYYExacHFNY\nBdwF4OkiKlfVegBVbQcOi8gEz7mXAyoi00TkSc81N+CeldTpYIzdzra084tlOznb0s7SG4WxuWnB\neFpjjAkrjrUUVHWDiGwTkQ1AJ/CgiCwFalV1OfA94CnPoPMu4FXPpdEishloBu5xKj5vnS4Xv311\nLyeqm1g0YzRXF+UG42mNMSbsODqmoKqP+Oza4XXsIHBND5ctdTKmnvx13RG2HzzF5IIM7p4/LthP\nb4wxYWPQ11bYur+SVzccJXtoIt9cUnTRq6cZY8xAMKg/AcsqG/j9yn0kxMXwnTunkjIkLtQhGWNM\nSA3apNBwto3Hl+2kpa2DBxZPYlR2SqhDMsaYkBu0SeG5tz/hVG0zt1xdwOUyPNThGGNMWBi0VVIL\nRqSSlhzPkjlWkM4YY7oM2qSw6Er/FsoxxpjBZNB2HxljjDmXJQVjjDHdLCkYY4zpZknBGGNMN0sK\nxhhjullSMMYY082SgjHGmG6WFIwxxnSLcrlcoY7BGGNMmLCWgjHGmG6WFIwxxnSzpGCMMaabJQVj\njDHdLCkYY4zpZknBGGNMN0sKxhhjug3aRXacICL/AczB/br+m6q+7HXsKFAKdHh23aOqx0MQ4zzg\nJWCPZ9cuVf2O1/HrgP+DO87XVfXRYMfoieN+4D6vXVeoaorX8TbgA6/jC1W1gyASkSLgr8BjqvpL\nERkNPAPEACeA+1S1xeeax4CZgAt4WFW3hCjOPwBxQBtwr6qe9Dp/Huf5GwlyrE8BlwPVnlN+qqor\nfa4Jh9f0JSDbczgT2KSqX/c6fynwKHDIs+ttVf1Xp+O8GJYUAkRE5gNFqjpLRLKAj4GXfU67UVUb\ngh/dOdaq6l29HHscuB44DqwVkWWqujd4obmp6u+B3wOIyFzg8z6n1KrqvGDH1UVEkoFfAO947f4J\n8ISqviQi/wf4GvDfXtfMBSZ4/kYmAU8Cs0IQ578Av1HVF0XkQeD7wN/5XHq+vxFH9BIrwN+r6mu9\nXBMWr6mq3u11/Engdz1c+oKq/sDJ2ALBuo8C532g6w/jDJAsIjEhjOeCiUghcFpVS1W1E3gdWBji\nsAB+hPtbVjhpAW4Cyr32zQNe8fz8KnCdzzULgRUAqroPyBCRNGfD7DHObwPLPD9XAVkOx+CvnmLt\nS7i8pgCIiABDVXWzwzE4xloKAeLpumj0bN6Pu+vFtzvj1yJSAKzH/e0nVDVGJovIK7ibuT9W1bc9\n+0fg/pDoUgmMC3Zw3kRkBlDq3b3hkSgizwFjgGWq+vNgxqWq7UC7+zOgW7JXd1ElkOtz2Qhgm9d2\nlWdfXTDjVNVGAM+Xlgdxt3B89fY34pheXlOAh0Tk+7hf04dU9ZTXsbB4Tb08jLsV0ZO5IvIm7m67\nH6jqxw6F2C/WUggwEVmCOyk85HPoR7ib6fOAIuDO4EbW7QDwY2AJ8FXg9yIS38u5UUGLqncPAE/1\nsP8HwNeBRcA9InJFMIPygz+vXcheX09CeAZYo6q+3TUX8jfitGeAR1R1AbAd+Oc+zg/laxoPXKOq\n7/ZweBPwz6p6A/BD4I9BDe4CWEshgETkeuAfgRtUtdb7mKr+0eu814Fi4C/BjRA8g9sveDYPichJ\nIA84grs5PMLr9DwurCnvhHnAOYOcqvrrrp9F5B3cr+fW4IXVowYRGaKqZ+n5tfN9fUfiHpAOhT8A\nB1T1x74H+vgbCSqfhPUKXmM0HuH0ms4Feuw2UtX9wH7PzxtFJFtEYoI9OcIf1lIIEBFJB34KLFbV\n077HROQtr29bc4HdwY7RE8s9IvIDz88jgBzcg8qo6lEgTUQKRCQWWAysCkWcnvhGAg2q2uqzX0Tk\nORGJ8sQ5m09nyoTSaj5tAd4JvOlzfBVwF4CITAfKVbU+eOG5icg9QKuq/lNvx3v7Gwk2EVnmGesC\n9xcE3/dNWLymHjOAHT0dEJG/E5EveX4uAqrCMSGAtRQC6QvAMOBFr77GNbin8y33tA42ichZ3DOT\ngt5K8HgFeM7TzRUPfAv4sojUqupyz/bznnNfUNVPQhQnuPvkK7s2ROQR3LNiNopIKe5vZZ3AK8Ee\n2BORy4GfAQVAm4jcBdwDPCUi3wCOAU97zv0z8DequkFEtonIBk/cD4YozuFAs4i85zltr6p+uytO\nevgb8U3MQYz1F8ALItIENHjiC8fX9A7cf6+HfM79q6ouAZ4DnhGRb+L+3L3f6Tgvlq2nYIwxppt1\nHxljjOlmScEYY0w3SwrGGGO6WVIwxhjTzZKCMcaYbpYUjOmBiMwTkfUBfLwCESkL1OMZ4xRLCsYY\nY7rZzWvG9EFEpgLP4i59XubZdzPu2v2LPNvX4L6haRbwa+ASIAH4UFW/6/N4TwHrVfV3nm0X7iJp\n0cATwHggFXheVX/m+C9ojBdrKRhzHiIyCnfxsru7EoLHW0CRiGR6tr+Au3hbBrBTVa9V1auARZ6y\nBv54GHeZhvnAVcAXPQnJmKCxloIxvUvFvabE//YUNOumqu0ishy4zfPNfwkwHfdaGqNFZCPuuvu5\nuMuf+LO40nxglGfhGIBE3K2GnQH4XYzxiyUFY3pXgHv1t/8lIq96Fh7y9hzuqrhHgB2qespTbG4G\nMMeTOHqq3NpdW8anJHUL8BNVDVVdLGOs+8iY89ilqt/HXSH0H3s4vgEoBO7F3XUE7oqi6kkIl+P+\npp/gc10dMNrz80I+TRLr8Sw7KiLRIvJzr+4pY4LCkoIxffsWcJ+IXO2907Ny3jLgNj5dhvMlYJaI\nrMVdPvv/4V73OsPr0idxjxe8C1wKdK298QTuNRk24l6U5YxvGXZjnGZVUo0xxnSzloIxxphulhSM\nMcZ0s6RgjDGmmyUFY4wx3SwpGGOM6WZJwRhjTDdLCsYYY7r9/++lG2zQAd7UAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f23f0d39f60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2zEyU7h7c4Uc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the above plot, the optimum value for k is 8."
      ]
    },
    {
      "metadata": {
        "id": "1DLcm8PJgirD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28f0463f-17a6-4575-8830-077693e5e2ab"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_knn = KNeighborsClassifier(n_neighbors=8)\n",
        "accuracy_knn = cross_val_score(autoimmune_knn, X, y, cv=10).mean()\n",
        "print(\"Accuracy using knn is {}\".format(accuracy_knn))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using knn is 0.7635964912280702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5e-N3AVO8wrK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalising the data"
      ]
    },
    {
      "metadata": {
        "id": "awoKHfxk6AAJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The accuracy can be increased by normalising/scaling the data.\n",
        "\n",
        "**Scaling**:  Shifting the distribution of the data to have zero mean\n",
        "\n",
        "**Normalizing**: Rescaling the data into the range 0 to 1.\n",
        "\n",
        "In below example we are going to scale the data, i.e. make the mean of each column zero (or close to zero)"
      ]
    },
    {
      "metadata": {
        "id": "iaKxGuzo8107",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "eda9d473-3ce1-4c9a-8e2e-d8f693908037"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "X_scaled = preprocessing.scale(X)\n",
        " \n",
        "X_scaled.mean(axis=0) # axis=0 indicated that mean should be taken wrt col"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.11022302e-16,  3.68499557e-16,  0.00000000e+00,  0.00000000e+00,\n",
              "        7.08652994e-18,  6.37787695e-17,  9.44870659e-18,  3.77948264e-17,\n",
              "       -1.32281892e-16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "mCqx1GK2By_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Not lets train the model using the scaled data"
      ]
    },
    {
      "metadata": {
        "id": "EmCQXl2h9NrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1a2cdea-eaad-42bd-d2b1-77dfb2347e62"
      },
      "cell_type": "code",
      "source": [
        "autoimmune_knn = KNeighborsClassifier(n_neighbors=8)\n",
        "accuracy_knn = cross_val_score(autoimmune_knn, X_scaled, y, cv=10).mean()\n",
        "print(\"Accuracy using knn is {}\".format(accuracy_knn))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using knn is 0.7634502923976608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3oTeYQPCtVk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now lets do the 10 fold cross validation on the normalised data. Instead of repeating the above loop for normalised data we will use GridSearchCV."
      ]
    },
    {
      "metadata": {
        "id": "naGzRxIGCbbW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GridSearchCV"
      ]
    },
    {
      "metadata": {
        "id": "1nxMCuwLCmUg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All the above tasks of running a with a range of k values and each time executing a 10-fold cross validation. This loop can be replace with GridSearchCV, which will do all the tasks in one statement."
      ]
    },
    {
      "metadata": {
        "id": "f3sGbgEMDDr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ah8O-ZG0DUtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ed88217-1a59-41f2-f241-01f1d90f9e4f"
      },
      "cell_type": "code",
      "source": [
        "parm_grid = dict(n_neighbors=range(1, 20))\n",
        "print(parm_grid)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_neighbors': range(1, 20)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8i2ZUA1zEemF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below GridSearchCV to execute the 10 fold cross validation for each value of k and fits the model with optimum k value."
      ]
    },
    {
      "metadata": {
        "id": "cDMoSK1dD7E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "e70443f2-0c4d-4c5f-f6b1-5ecb1bbbabeb"
      },
      "cell_type": "code",
      "source": [
        "model_scaled = GridSearchCV(autoimmune_knn, parm_grid, cv=10)\n",
        "model_scaled.fit(X_scaled, y)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score='raise',\n",
              "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
              "           weights='uniform'),\n",
              "       fit_params=None, iid=True, n_jobs=1,\n",
              "       param_grid={'n_neighbors': range(1, 20)}, pre_dispatch='2*n_jobs',\n",
              "       refit=True, return_train_score='warn', scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ro5pZIWFb_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "9b0c5650-def8-4cd7-fd9f-7c7a04ca2d15"
      },
      "cell_type": "code",
      "source": [
        "model_scaled.grid_scores_"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[mean: 0.69947, std: 0.07922, params: {'n_neighbors': 1},\n",
              " mean: 0.73404, std: 0.06490, params: {'n_neighbors': 2},\n",
              " mean: 0.76330, std: 0.05063, params: {'n_neighbors': 3},\n",
              " mean: 0.75532, std: 0.05874, params: {'n_neighbors': 4},\n",
              " mean: 0.77394, std: 0.04719, params: {'n_neighbors': 5},\n",
              " mean: 0.76596, std: 0.06521, params: {'n_neighbors': 6},\n",
              " mean: 0.76596, std: 0.07531, params: {'n_neighbors': 7},\n",
              " mean: 0.76330, std: 0.07468, params: {'n_neighbors': 8},\n",
              " mean: 0.75798, std: 0.07426, params: {'n_neighbors': 9},\n",
              " mean: 0.73670, std: 0.05992, params: {'n_neighbors': 10},\n",
              " mean: 0.75000, std: 0.06141, params: {'n_neighbors': 11},\n",
              " mean: 0.74734, std: 0.04483, params: {'n_neighbors': 12},\n",
              " mean: 0.75000, std: 0.04676, params: {'n_neighbors': 13},\n",
              " mean: 0.75532, std: 0.05400, params: {'n_neighbors': 14},\n",
              " mean: 0.75798, std: 0.05283, params: {'n_neighbors': 15},\n",
              " mean: 0.75798, std: 0.06206, params: {'n_neighbors': 16},\n",
              " mean: 0.75798, std: 0.05663, params: {'n_neighbors': 17},\n",
              " mean: 0.76330, std: 0.05071, params: {'n_neighbors': 18},\n",
              " mean: 0.76862, std: 0.06573, params: {'n_neighbors': 19}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9vkwjA6Ikbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06bb7cde-8205-4bc7-9872-7ae2dd1d26a8"
      },
      "cell_type": "code",
      "source": [
        "print(\"Best Score for normalised data : {} for {}\".format(model_scaled.best_score_, model_scaled.best_params_))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score for normalised data : 0.773936170212766 for {'n_neighbors': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2RNTDFb1GXjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d5c810c7-27ad-4f78-b324-a153a1a38799"
      },
      "cell_type": "code",
      "source": [
        "model_raw = GridSearchCV(autoimmune_knn, parm_grid, cv=10)\n",
        "model_raw.fit(X, y)\n",
        "model_raw.grid_scores_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:762: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[mean: 0.68617, std: 0.07039, params: {'n_neighbors': 1},\n",
              " mean: 0.69415, std: 0.05343, params: {'n_neighbors': 2},\n",
              " mean: 0.69149, std: 0.06884, params: {'n_neighbors': 3},\n",
              " mean: 0.72606, std: 0.05191, params: {'n_neighbors': 4},\n",
              " mean: 0.72872, std: 0.03958, params: {'n_neighbors': 5},\n",
              " mean: 0.74202, std: 0.03464, params: {'n_neighbors': 6},\n",
              " mean: 0.75000, std: 0.03488, params: {'n_neighbors': 7},\n",
              " mean: 0.76330, std: 0.04509, params: {'n_neighbors': 8},\n",
              " mean: 0.75266, std: 0.03752, params: {'n_neighbors': 9},\n",
              " mean: 0.74202, std: 0.05069, params: {'n_neighbors': 10},\n",
              " mean: 0.75532, std: 0.04173, params: {'n_neighbors': 11},\n",
              " mean: 0.76064, std: 0.03780, params: {'n_neighbors': 12},\n",
              " mean: 0.76064, std: 0.05218, params: {'n_neighbors': 13},\n",
              " mean: 0.73670, std: 0.06461, params: {'n_neighbors': 14},\n",
              " mean: 0.75532, std: 0.05400, params: {'n_neighbors': 15},\n",
              " mean: 0.74734, std: 0.06709, params: {'n_neighbors': 16},\n",
              " mean: 0.75532, std: 0.06233, params: {'n_neighbors': 17},\n",
              " mean: 0.75266, std: 0.05361, params: {'n_neighbors': 18},\n",
              " mean: 0.75532, std: 0.06405, params: {'n_neighbors': 19}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "tGcQUpNIIeV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cebaf510-19d8-489b-98a7-d5a43d1fb079"
      },
      "cell_type": "code",
      "source": [
        "print(\"Best Score for normalised data : {} for {}\".format(model_raw.best_score_, model_raw.best_params_))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score for normalised data : 0.7632978723404256 for {'n_neighbors': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bLqO--LMHTQt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After applying various tunings to the model, an accuracy of 77.3 has been achieved with k=5 and normalizing the data."
      ]
    },
    {
      "metadata": {
        "id": "F6p3XTZKhLhb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "C8ZNANHahSO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d04a43cd-5463-4ee1-cb4e-55dc22129825"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "autoimmune_log_reg = LogisticRegression()\n",
        "accuracy_log_reg = cross_val_score(autoimmune_log_reg, X, y, cv=10).mean()\n",
        "print(\"Accuracy using Logistic Regression is {}\".format(accuracy_log_reg))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Logistic Regression is 0.7818713450292398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UrFjBokmiizY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the above models, there is no signicant difference in accuracy between Logistic Regression and kNN, but Logistic Regression seems to perform better than kNN."
      ]
    }
  ]
}